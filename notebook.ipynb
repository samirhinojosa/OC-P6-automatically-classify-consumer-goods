{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08bc296-b953-4e67-b675-0a799b1677dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; background-color: #3F579F;\">\n",
    "    <h1 style=\"margin: auto; font-weight: bold; padding: 30px 30px 0px 30px;\" align=\"center\">Automatically classify consumer goods - P6</h1>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 5px 30px 0px 30px;\" >\n",
    "    <h3 style=\"width: 100%; text-align: center; float: left; font-size: 24px;\" align=\"center\">| Notebook |</h3>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 10px 30px 30px 30px;\">\n",
    "    <h4 style=\"width: 100%; text-align: center; float: left; font-size: 24px;\" align=\"center\">Data Scientist course - OpenClassrooms</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15875b00-1c19-4742-a494-e7b8aaa37fe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">1. Libraries and functions</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c59a62-17d6-4cd4-a4d0-a9e197eedc22",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">1.1. Libraries and functions</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c987284-6588-493d-8d3f-cee6272f6351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Samir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Samir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "## General\n",
    "import ast\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "from itertools import islice\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "## Scikit Learn \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "## Computer vision library\n",
    "import cv2\n",
    "\n",
    "## TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "## Own specific functions \n",
    "from functions import *\n",
    "from functions_nlp import *\n",
    "from functions_img import *\n",
    "\n",
    "## Images paths\n",
    "ORIGINAL_IMAGES_PATH = \"images/Flipkart/\"\n",
    "THUMBNAILS_IMAGES_PATH  = \"images/Flipkart/thumbnails/\"\n",
    "CB_IMAGES_PATH = \"images/Flipkart/thumbnails/contrast_and_brightness/\" # path images with contrast and brightness edit\n",
    "GRAY_IMAGES_PATH = CB_IMAGES_PATH + \"gray_images/\"\n",
    "NR_IMAGES_PATH = GRAY_IMAGES_PATH + \"noise_reduction/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8785b2-50be-4a0f-8f12-035bef2f3f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21576/2906108151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'XX' is not defined"
     ]
    }
   ],
   "source": [
    "XX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114ab61-f7ce-46cb-9cf5-1607a77f6055",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">2. Importing files and Initial analysis</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f33ae-6c67-41e1-a821-dd694e3c7938",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">2.1. Importing and preparing files</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805a284-b2db-47e8-bde4-44440a51f284",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    We are going to load the dateset resulting from the RFM\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3d4ac-0632-44c2-a8e0-ac10b9712242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"datasets\\flipkart_com-ecommerce_sample_1050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1e69b-51d4-41cf-a31b-820a3d1a1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252417d-2bfe-472a-be5f-f95a04d90345",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">2.2. Initial analysis</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac074185-00a0-4f7c-a777-6f488681e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis(data, \"data\", columns=[\"uniq_id\"], analysis_type=\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14868c1-f115-41d8-8b46-c991652d32db",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Plotting the percentage of missing values by features</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd035d-c9b8-4942-99a3-88829f4d9be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isnull().sum(axis=0).sort_values(ascending=False)/len(data.index)*100\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plot = sns.barplot(x=missing_values.index.tolist(), y=missing_values.values.tolist())\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".1f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=missing_values.index.tolist(), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"%\", size=12)\n",
    "plt.xlabel(\"Features\", size=12)\n",
    "plt.title(\"Missing values percentage by feature\", size=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/text_analysis/missing-values-percentage-by-feature.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8011db-a556-491b-80bf-728b6e5dc8c8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <ul>\n",
    "        <li>There are some features that are not important to our text analysis. For example, pid, uniq_id, etc.</li>\n",
    "        <li>The missing value percentage is higher only in one feature.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73cb03-1dad-4887-8059-73ee96b360a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">3. Selecting the features to work</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e719ccbc-5e72-4d7b-ac7f-938b1868811b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.1. Analyzing the features</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02842532-d5a5-4e50-92b8-45548c0995c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73c759-e824-4df3-b945-e88fc9e2eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709668bf-78d0-4353-a819-e61a6a6bccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546e39bb-648e-4e43-9b0e-9e21a48cf623",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">3.1.1. Brand</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac4a29-b582-41f8-a72d-b9eebdaafbc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's analyze in detail the feature <b>brand</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447840b3-9fbc-497d-985d-929afa9ef82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"brand\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69a6a7-92b5-4ac4-8cd3-49c7eafcd7c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>It seems that it does not add value to the problem. It contains the names of brands and probably it does not add value to classify images</p>\n",
    "    <p>Despite that, we are going to keep it</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc817d51-2c40-4f0f-9d5a-8df00197a190",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">3.1.2. Retail price</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7dcc4-0a98-4910-81ed-051323ec5605",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's analyze in detail the feature <b>brand</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8e1a5-59e9-4923-988f-877e91fccf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_histogram_qqplot(data[\"retail_price\"], \"Retail price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74f9ca-7db6-49f2-bf4a-e87a6a18cc11",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Retail price doesn't have a normal distribution.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711fdd04-302a-4587-b43c-dd6de883a34b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.2. Selecting the features</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852805a4-5e3f-49a2-803b-56bba5dd1e51",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>To select the features, first, we are going to <b>discard features</b> that do not add value to the problem</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li><b>crawl_timestamp</b></li>\n",
    "        <li><b>product_url</b></li>\n",
    "        <li><b>pid</b></li>\n",
    "        <li><b>is_FK_Advantage_product</b></li>\n",
    "        <li><b>product_rating</b></li>\n",
    "        <li><b>overall_rating</b></li>\n",
    "        <li><b>discounted_price</b></li>\n",
    "    </ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6f21f-6848-4238-98a7-fb5c259fdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = data.drop(columns=[\"crawl_timestamp\", \"product_url\", \"pid\", \"is_FK_Advantage_product\",\n",
    "                             \"product_rating\", \"overall_rating\", \"discounted_price\"],\n",
    "                    axis=0).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02531d3d-b661-4620-b2e5-e3e07e701396",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>For now, we are going to keep the following features</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li><b>uniq_id</b> - we can use this feature to keep relations on the data</li>\n",
    "        <li><b>product_name</b></li>\n",
    "        <li><b>product_category_tree</b></li>\n",
    "        <li><b>description</b></li>\n",
    "        <li><b>retail_price</b></li>\n",
    "        <li><b>brand</b></li>\n",
    "        <li><b>product_specifications</b></li>        \n",
    "    </ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9c840-b70f-4e8b-b118-ebbb877bbf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85b06d-ea35-4070-8158-bc998ef7728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfad66-d688-498f-9228-38f60df8448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10322f29-4cf3-4682-8878-67ec74c74152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis(df_data, \"df_data\", type_analysis=\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa21c88-1b5f-47f0-94c4-ada4e38d9bad",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Now, we have a dataset with the following characteristic</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>30% missing-values in <b>brand</b></li>\n",
    "        <li>One cell with missing-value in <b>retail_price</b></li>\n",
    "    </ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0371dac-4cb2-4b95-9f8c-3dd80bcb6b58",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">3.2.1 Continuous Variables Transformation</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428411d-1225-4135-9e34-369314cef56a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We are going to apply Logarithmic transformation on <b>retail_price</b> to get a better Normal distribution</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4179a4-8054-45a6-9fb8-7abcc97dab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"retail_price_log\"] = np.log(df_data[\"retail_price\"])\n",
    "df_data[\"retail_price_log2\"] = np.log2(df_data[\"retail_price\"])\n",
    "df_data[\"retail_price_log10\"] = np.log10(df_data[\"retail_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7889d5-2aba-4daf-80e4-b0583bdf22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_histogram_qqplot(df_data[\"retail_price_log\"], \"Retail price log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf256a6-90b9-4fc3-92f7-288dc8508368",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_histogram_qqplot(df_data[\"retail_price_log2\"], \"Retail price log2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc9e84-0e8c-444e-beba-1dd87d38726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_histogram_qqplot(df_data[\"retail_price_log10\"], \"Retail price log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c9e85-ca49-46a3-8466-575d6fc94cf4",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Log2 has the higher variance </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6b448-b7ee-4a47-8a2c-28b7a6a3fc16",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Deleting others columns related to price</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf110c-5fcd-4dd4-8cce-e6f7eba0791a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data.drop(columns=[\"retail_price\", \"retail_price_log\", \"retail_price_log10\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8056b2-8453-407e-b0e7-a9b5167f244e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">4. Treating missing-values</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5695453-9e79-4b42-9c99-ed063cd657a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>To treat missing-values</b>, we are going to do as follows</p>\n",
    "    <ol>\n",
    "        <li>Fill missing-vallues in <b>brand</b> and <b>product_specifications</b> with empty-value.</li>\n",
    "        <li>Fill missing-vallues in <b>retail_price</b> based on the median for the same <b>product category</b>.</li>\n",
    "    </ol>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>So, Being the feature called <b>brand</b> only one missing-value, let's proceed to complete it with empty-value</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1d92a-8d10-40e1-8571-191ff7f983e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"brand\"].fillna(\"\", inplace=True)\n",
    "df_data[\"product_specifications\"].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a43ccec-1595-4f7a-9f6c-14eaa159ed77",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">4.1. Analyzing \"product_category_tree\"</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67ff9a-593a-456d-b1e7-b7817de233ce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's analyse the levels of the tree in <b>product_category_tree</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b166fb-8c83-4428-9406-436a7a1a6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 10, 100, 1049]:\n",
    "    print(df_data.loc[i, \"product_category_tree\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d66598-3728-4a45-8ebc-d7d100ee1cca",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>The levels in the tree does not seem equals in all records</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6c55f-453d-4f99-a7b4-f1f9fc473442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"tree_levels\"] = df_data[\"product_category_tree\"].str.count(\">>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b0972-b788-4024-a3b2-19ffa66ee557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"tree_levels\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9adb6a-4282-4f58-bdf3-a7fe6c9ae886",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b9c14-a493-4fc7-a1c1-50b232566c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.query(\"tree_levels == tree_levels.min()\").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d113575-08df-44a6-80c1-adac0f1e821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.query(\"tree_levels == tree_levels.max()\").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b099ef-2ad3-49b0-89be-7484c7f48027",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb59fb-69aa-4c8f-bde7-3a389d8e6d4b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>There are from 2 until 6 levels in <b>product_category_tree</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e96228-9447-4450-9f16-8cb1585cce1d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's analyze the 2 first levels that are common in all records</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cff92-70ea-493e-886d-92294d8afdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"category_1\"] = df_data[\"product_category_tree\"].apply(lambda x :x.split('>>')[0][2:len(x.split(\">>\")[0])])\n",
    "df_data[\"category_1\"] = df_data[\"category_1\"].apply(lambda x :x.strip())\n",
    "\n",
    "df_data[\"category_2\"] = df_data[\"product_category_tree\"].apply(lambda x :x.split('>>')[1])\n",
    "df_data[\"category_2\"] = df_data[\"category_2\"].apply(lambda x :x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09257626-3e40-474e-8c78-e7d9998e58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495eee5-f0dc-4e9a-afed-202000d28ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique categories in level 1:\", df_data[\"category_1\"].nunique())\n",
    "print(\"Unique categories in level 2:\", df_data[\"category_2\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7bc29-b887-4482-8a6b-d84ecc96db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_and_pie(df_data[\"category_1\"], \"Categories level 1\", \"Categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4c52f-a016-45e2-932b-aa7f7bd54c89",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Based on the plot, we can ask whether we will get 7 clusters in our modeling? </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e387bb-48fc-4c6f-a789-c5755476047b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's see the record with <b>retail_price</b> missing-value</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf7b32-e18d-45f6-bedf-390bb17af140",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_and_pie(df_data[\"category_2\"], \"Categories level 2\", \"Categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495477c-8178-4153-8425-d2546765ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[df_data[\"retail_price_log2\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e56029-9dec-400d-a687-98bd228f3b2b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>Let's get to the mean of the <b>retail_price</b> based on the firsts two categories in the tree</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad86ab-e577-4855-b01f-05a1a0a92c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_price_mean = df_data[(df_data[\"category_1\"]==\"Baby Care\") & (df_data[\"category_2\"]==\"Baby Bath & Skin\")][\"retail_price_log2\"].mean()\n",
    "print(\"retail_price_mean:\", retail_price_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40dacd-b684-4f12-a7bf-1106e4a1a15e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's replace the missing-value into <b>retail_price</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a74c0e-aec2-4e26-aac5-92002d9b7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"retail_price_log2\"].fillna(retail_price_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89044011-c474-450a-a237-df87a4e8cb0d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's proceed to delete the categories features added</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b370839-9b99-4e0c-84ce-ea3f331ca669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.drop(columns=[\"tree_levels\", \"category_2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8d697-7e29-4eea-86be-ccf27e266182",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's analyze the dataset</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf5311-121a-4225-a014-38019c812341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis(df_data, \"df_data\", type_analysis=\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a90d67a-df78-4ac5-906c-faa2bc2bde89",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this point, we have the dataset without missing-values.</p>\n",
    "    <p>Let's proced to make the normalization.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db744315-9d5c-4c05-9203-6cb467b03060",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">5. Pre-processing Text data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee070b-348c-49de-8957-fc6c380fa6d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We are going to process the following features</p>\n",
    "    <ol>\n",
    "        <li>product_name</li>\n",
    "        <li>product_category_tree</li>\n",
    "        <li>description</li>\n",
    "        <li>brand</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b29712-9129-4931-895b-72a7933b91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\n",
    "    \"product_name\", \"product_category_tree\",\n",
    "    \"description\", \"brand\", \"product_specifications\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23704951-9ab3-4866-9991-2668592e5a86",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">5.1. Analyzing the characters in the features</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b694be4-ed90-4293-83f4-bd2df240984e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Before doing the steps above, let's check what type of character we have in the dataset.<br>Then we can use the appropriate tokenizer</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b4917-65ae-4322-9113-7a5c14182e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_type = [\"numerical\", \"special\"]\n",
    "\n",
    "for col in text_columns:\n",
    "    \n",
    "    # checking the character in each sample by feature\n",
    "    df_data[col + \"_check\"] = df_data[col].apply(lambda x: check_characters(x))\n",
    "    \n",
    "    # Normalizing to column, the dict in the sample\n",
    "    globals()[\"df_\" + col + \"_check\"] = pd.json_normalize(df_data[col + \"_check\"])\n",
    "    \n",
    "    # Counting the characters uniques by feature\n",
    "    for val in character_type:\n",
    "        globals()[\"dict_\" + col + \"_\" + val] = {}\n",
    "\n",
    "        for i in globals()[\"df_\" + col + \"_check\"][val]:\n",
    "            for j in i:\n",
    "                if j not in globals()[\"dict_\" + col + \"_\" + val]:\n",
    "                    globals()[\"dict_\" + col + \"_\" + val][j] = 1\n",
    "                else:\n",
    "                    globals()[\"dict_\" + col + \"_\" + val][j] += 1\n",
    "                    \n",
    "        # Sorting dict by value descending\n",
    "        globals()[\"dict_\" + col + \"_\" + val] = sorted(globals()[\"dict_\" + col + \"_\" + val].items(),\n",
    "                                                      key=operator.itemgetter(1), reverse=True)\n",
    "        globals()[\"dict_\" + col + \"_\" + val] = {k:v for k, v in globals()[\"dict_\" + col + \"_\" + val]}\n",
    "        \n",
    "        # Creating dataset based on the dict\n",
    "        if val == \"special\":\n",
    "            globals()[\"df_\" + col + \"_\" + val] = pd.DataFrame({\"character\" : list(globals()[\"dict_\" + col + \"_\" + val].keys()),\n",
    "                                                              \"number\" : list(globals()[\"dict_\" + col + \"_\" + val].values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105d78f-2626-45ad-b5e4-f4aed1e18de4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Plotting the special characters in <b>description</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1231b0f-066f-43d0-8e3e-06bc162bbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "plot = sns.barplot(x=df_description_special[\"character\"], y=df_description_special[\"number\"])\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".1f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plt.ylabel(\"Number\", size=12)\n",
    "plt.xlabel(\"character\", size=12)\n",
    "plt.title(\"Special characters in \\\"description\\\"\", size=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e3c45-dcca-4bb8-a77f-dfa4a10c7459",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Plotting the special characters in <b>product_category_tree</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb09405-4967-4c8e-b75f-0bc811afbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "plot = sns.barplot(x=df_product_category_tree_special[\"character\"], y=df_product_category_tree_special[\"number\"])\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".1f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plt.ylabel(\"Number\", size=12)\n",
    "plt.xlabel(\"character\", size=12)\n",
    "plt.title(\"Special characters in \\\"product_category_tree\\\"\", size=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf3169-c378-4895-8777-5c1a23347b51",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Plotting the special characters in <b>product_specifications</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2c4bb-e9e6-44fb-801f-3ca84df2f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "plot = sns.barplot(x=df_product_specifications_special[\"character\"], y=df_product_specifications_special[\"number\"])\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".1f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plt.ylabel(\"Number\", size=12)\n",
    "plt.xlabel(\"character\", size=12)\n",
    "plt.title(\"Special characters in \\\"product_specifications\\\"\", size=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4cf21e-b7a2-45d0-9fde-065e9c691468",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Printing the digit characters in <b>product_name</b>, <b>product_category_tree</b>, <b>description</b>, <b>brand</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79f269-7dd0-441a-a73a-e1bf7bdea3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_columns:\n",
    "    print(col + \" has \" + str(len(globals()[\"dict_\" + col + \"_numerical\"])) + \" digit used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ac824-9b03-4f08-8404-51369be2913d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>The 4 features have used numerical characters.</li>\n",
    "        <li>It seems there are contractions in the text so, it is necessary to check this point.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e5353-ae16-4d79-b283-ab7b7eba7e0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Deleting the datasets</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008ec99-7971-4a7d-84a9-7dd642cc297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_columns:\n",
    "    \n",
    "    del globals()[\"df_\" + col + \"_check\"]\n",
    "    del globals()[\"df_\" + col + \"_special\"]\n",
    "    \n",
    "    del df_data[col + \"_check\"]\n",
    "        \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664019c-8913-4ecd-b98b-38c39c24207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd9c9b-7730-4fb7-b863-9e1be7bea3be",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.1.1. Checking contractions</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033b23b-548c-4572-905e-74ee245fcdca",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's check some contractions in the description</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90387773-4f28-4cab-a5e0-ee81e3f8ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_check = [\"\\'re\", \"\\'d\", \"\\'t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d30c6d-a21b-4fbc-aea9-4998f7ec79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_characters = df_data[[\"description\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1dfce-5484-4ae3-ac59-b8197706837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae9a89-07d2-4bda-8492-c0816a463944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_characters[df_check_characters[\"description\"].str.contains(\"|\".join(characters_to_check))].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb2e33-a24f-4144-af78-687faef163ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242fff8-ba33-4cc5-b111-126ea7838516",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Deleting the dataset</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1011770-fee9-4d24-8105-05e769c76309",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_check_characters\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604f0a5-d520-41fa-be7b-e05a764b4fc7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this point, we can see in the text:</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>Characters for new line, tabs, etc..</li>\n",
    "        <li>There are contractions in the descriptions.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d968ff8-043f-4d2d-9cc2-a5e1355fb430",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">5.2. Tokenization</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41afc89-4eef-4a41-9698-5fce7145dd99",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>To tokenize the text, we are going to do the following</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>Cleaning up the text</li>\n",
    "        <li>Remove stop words</li>\n",
    "    </ul>\n",
    "    <p>Finally, we are going to compare the results</p>\n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d682036-097f-416d-87ae-ad4367de5934",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.2.2. Cleaning up the text</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee7c94-eb64-483b-9c00-5e6c0156b79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>To clean up the text, we are going to remove the following</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>Newlines, tabs, etc.</li>\n",
    "        <li>HTML tags</li>\n",
    "        <li>Extra whitespace</li>\n",
    "        <li>Emails</li>\n",
    "        <li>Accented characters</li>\n",
    "        <li>Incorrect characters</li>\n",
    "        <li>Punctuations</li>\n",
    "        <li>Non alphabet characters</li>\n",
    "    </ul>\n",
    "    <p>Also, we are going to do: </p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>To transform to lowercase.</li>\n",
    "        <li>To expand contractions</li>\n",
    "    </ul>\n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903aa645-a399-4329-beab-ff2ad97d1bfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Reading a english contractions dictionay</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e815cd-9ddd-475d-a77c-056ddc6b44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasets\\english_contractions.txt\")\n",
    "contents = file.read()\n",
    "english_contractions = ast.literal_eval(contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eddc8d5-86e2-492b-9585-ea517f5d10fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's cleaning the features</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf7ae8-095a-4a30-8f40-aeeaa054aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tokens_by_feature, cleaned_words_by_feature = [{} for i in range(2)]\n",
    "for col in text_columns:\n",
    "    \n",
    "    # Tokenization of text without clean\n",
    "    df_data[col + \"_initial\"] = df_data[col].apply(lambda x: tokenizer(x))\n",
    "    initial_tokens_by_feature[col] = df_data[col + \"_initial\"].explode().dropna().value_counts().shape[0]\n",
    "    del df_data[col + \"_initial\"]\n",
    "    \n",
    "    # Tokenization of text after cleanning\n",
    "    if col == \"product_specifications\":\n",
    "        df_data[col + \"_cleaned\"] = df_data[col].apply(lambda x: cleaning_up_product_specifications(x))\n",
    "        df_data[col + \"_cleaned\"] = df_data[col + \"_cleaned\"].apply(lambda x: cleaning_up_text(x, english_contractions))\n",
    "    else:    \n",
    "        df_data[col + \"_cleaned\"] = df_data[col].apply(lambda x: cleaning_up_text(x, english_contractions))\n",
    "    \n",
    "    cleaned_words_by_feature[col] = df_data[col + \"_cleaned\"].explode().dropna().value_counts().shape[0]\n",
    "    \n",
    "    \n",
    "# Sorting dict by value desc\n",
    "initial_tokens_by_feature = sorted(initial_tokens_by_feature.items(), key=operator.itemgetter(1), reverse=True)\n",
    "initial_tokens_by_feature = {k:v for k, v in initial_tokens_by_feature}\n",
    "\n",
    "cleaned_words_by_feature = sorted(cleaned_words_by_feature.items(), key=operator.itemgetter(1), reverse=True)\n",
    "cleaned_words_by_feature = {k:v for k, v in cleaned_words_by_feature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d20bfe-5532-433b-a3c3-08c77e2878e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d4232-c4ef-46f2-aeac-26f66d924463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec4513-e91e-4a54-b716-389c0c833c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d518dc79-842b-44f0-947a-2b64fcd8f14c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.2.2. Removing words</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ecb87-39ed-4e7d-88ad-a03a3b6c137e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to reduce words based on the following:</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>Stop words</li>\n",
    "        <li>Non english words</li>\n",
    "        <li>Keep Nouns</li>\n",
    "    </ul>    \n",
    "    <p>It must consider that the mission is not about sentiment analysis, it is about classification</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7288de-1040-4a89-8d02-3bb8b8708a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_words_by_feature = {}\n",
    "for col in text_columns:\n",
    "    df_data[col + \"_tokens\"] = df_data[col + \"_cleaned\"].apply(lambda x: remove_words(x, \"english\"))\n",
    "    reduced_words_by_feature[col] = df_data[col + \"_tokens\"].explode().dropna().value_counts().shape[0]\n",
    "\n",
    "    del df_data[col + \"_cleaned\"]\n",
    "    \n",
    "# Sorting dict by value descending\n",
    "reduced_words_by_feature = sorted(reduced_words_by_feature.items(), key=operator.itemgetter(1), reverse=True)\n",
    "reduced_words_by_feature = {k:v for k, v in reduced_words_by_feature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f2534-e07a-4748-8fbf-14c03ffaffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc3709-aa74-415e-b0fe-9ee15cd8b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d3fe8-acae-45fb-8e54-e32c8fcc9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c19ba-84f0-4992-ad69-6c4048f61364",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.2.3. Compare the results</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b49077-cb2a-4fe6-aaa7-593f200843aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's compare the number of words during the all process</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee811438-41f6-47f3-be26-9122d8e9b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Plot the total words tokenized\n",
    "sns.set_color_codes(\"pastel\")\n",
    "plot = sns.barplot(x=list(initial_tokens_by_feature.values()),\n",
    "                   y=list(initial_tokens_by_feature.keys()), \n",
    "                   label=\"Initial\", color=\"b\")\n",
    "\n",
    "# Plot the words tokenized after cleanning up\n",
    "sns.set_color_codes(\"muted\")\n",
    "plot = sns.barplot(x=list(cleaned_words_by_feature.values()),\n",
    "                   y=list(cleaned_words_by_feature.keys()),\n",
    "                   label=\"Intermediate\", color=\"b\")\n",
    "\n",
    "# Plot the words tokenized after reducing stop words\n",
    "sns.set_color_codes(\"dark\")\n",
    "plot = sns.barplot(x=list(reduced_words_by_feature.values()),\n",
    "                   y=list(reduced_words_by_feature.keys()),\n",
    "                   label=\"Final\", color=\"b\")\n",
    "\n",
    "plt.legend(ncol=3, loc=\"lower right\", frameon=True)\n",
    "plt.xlabel(\"Numbers of tokens\", size=12)\n",
    "plt.ylabel(\"Features\", size=12)\n",
    "plt.title(\"Number of tokens during all process\", size=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/text_analysis/number-of-tokens-during-process.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56293392-f2f4-45d9-be5e-e9873a1103f0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Here, we can see how the tokens have reduced during all process, being description the features with more tokens during the process</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ce781-e5d5-44ba-877c-1b36060071c0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">5.3. Stemming the tokens</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36261130-c7b9-48f8-9f4b-af4597fe6bf8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We use <b>Porter stemming algorithm</b> because it has a less agressive approach in comparison with <b>Plancaster stemming algorithm</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7848ca-b7db-4038-ba59-ae3403a84629",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_columns:\n",
    "    df_data[col + \"_stemmed\"] = df_data[col + \"_tokens\"].apply(lambda x: stem_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c6570-94fc-44fc-ae3c-431249a6b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2ea4e-76a5-4745-8f3f-be4d218b61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[[\"description\", \"description_tokens\", \"description_stemmed\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b458d-0e06-4b69-b26e-c26a5bb1fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell@nhurpertuzs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9f123-1625-43c1-ad09-7f81a4214693",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">5.4. Lemmatization the tokens</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634143f9-4b99-4620-8025-b0fe7bc8d42b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's do the lemmatization</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe86767-9350-46ef-9e24-7a896ac6b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_columns:\n",
    "    df_data[col + \"_lemma\"] = df_data[col + \"_tokens\"].apply(lambda x: lemma_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9230a3f-a0a8-434f-a75c-90493fce99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59632d18-990b-485f-83f1-8ee482d210aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[[\"description\", \"description_tokens\", \"description_stemmed\", \"description_lemma\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec618e5-8dfb-44a6-b2d7-9993c9396fd9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this point, we can see an example of text after doing all process</p>\n",
    "    <p>It seems that the lemmatization have got better results than stemming</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddf5d3-1483-496a-9f3c-39d630d545bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">5.5. Text Vectorization</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f2b96-e1e5-4c69-b7a7-1ef41b0dcbbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>First of all, let's see all features transformed</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5173d584-ba62-43d6-8b2f-51aa0446aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_columns:\n",
    "    \n",
    "    if col == \"description\":\n",
    "        head = 2\n",
    "    else:\n",
    "        head = 5\n",
    "    \n",
    "    print(\"-\"*200)\n",
    "    print(\" >> \" + col)\n",
    "    display(df_data[[col, col + \"_tokens\", col + \"_stemmed\", col + \"_lemma\"]].head(head))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81ec2f-ff8c-448a-91b3-e9965540a4a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this point, we can see how the features have been transformed</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201cb443-8c0f-46b4-a908-f82e00d0e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "pd.reset_option(\"display.float_format\") # reset show full content in cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef6efc-e6e0-4d93-9de3-10401242457a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.5.1. Thresholds lower frequency</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb148c71-b1d0-4578-8634-4c2dd464d47d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Before doing the <b>Text Vectorization</b>, let's analyse the number of words with lower frequency in each feature, to define the threshold (min_df) to tream them </p>\n",
    "    <p>To do that we are going to use BoW in default mode and plot the numbers of words with lower frequency</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8263568-0fb2-46f6-a099-ff10299e8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fb375-2fc2-42e8-92f2-d14bf229ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_columns:\n",
    "    \n",
    "    for var in [\"stemmed\", \"lemma\"]:\n",
    "        \n",
    "        globals()[\"bow_\" + col + \"_\" + var] = cv_vectorizer.fit_transform(df_data[col + \"_\" + var].astype(\"U\"))\n",
    "        globals()[\"df_bow_\" + col + \"_\" + var] = pd.DataFrame(globals()[\"bow_\" + col + \"_\" + var].toarray(),\n",
    "                                                              columns=cv_vectorizer.get_feature_names_out())\n",
    "        \n",
    "        if var == \"stemmed\":\n",
    "            palette = \"flare\"\n",
    "        else:\n",
    "            palette = \"crest\"\n",
    "        \n",
    "        # Plottint the results\n",
    "        most_frequent_words = (globals()[\"df_bow_\" + col + \"_\" + var].sum(axis=0)).sort_values(ascending=True)\n",
    "        globals()[\"df_lower_frequent_words_\" + col + \"_\" + var] = pd.DataFrame.from_dict({\"words\" : most_frequent_words.index,\n",
    "                                                                                          \"frequency\" : most_frequent_words.values})\n",
    "\n",
    "        lower_frequent_words = globals()[\"df_lower_frequent_words_\" + col + \"_\" + var].groupby(\"frequency\")[\"frequency\"].count().head(30)\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        plot = sns.barplot(x=lower_frequent_words.index, y=lower_frequent_words, palette=palette)\n",
    "        for p in plot.patches:\n",
    "            plot.annotate(format(p.get_height(), \".1f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "        plot.set_xticklabels(labels=lower_frequent_words.index, rotation=70, size=12,\n",
    "                                 horizontalalignment=\"right\")\n",
    "        plt.ylabel(\"Number of words\", size=12)\n",
    "        plt.xlabel(\"Frequency\", size=12)\n",
    "        plt.title(\"Numbers of words by frequency\\n(\" + col + \" - \" + var + \")\", size=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c63c2-3521-4593-8d19-bbbcc27bc068",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Now, we are going to define the following thresholds (min_df)</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>product_name: min_df=3</li>\n",
    "        <li>product_category_tree: min_df=3</li>\n",
    "        <li>description: min_df=5</li>\n",
    "        <li>brand: min_df=2</li>\n",
    "        <li>product_specifications:min_df=4</li>\n",
    "    </ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a9b48-20b3-4193-8125-1a5f02a3f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = {\n",
    "    \"product_name\": 3,\n",
    "    \"product_category_tree\": 3,\n",
    "    \"description\": 5,\n",
    "    \"brand\": 2,\n",
    "    \"product_specifications\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb165047-222f-4494-a9d6-a3fec6c03fbd",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.5.2. Bag of Word - BoW</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae8ec7-c11d-48b2-a9cf-4efa46df562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 25) # show full of showing cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c6ec3-7cb2-4853-9d2b-e88901de9211",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to do a BoW for each feature, considering the stemmed and lemma treatments</p>\n",
    "    <p>Let's initialize the CountVectorizer based on the min_df defined</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5717c-4efe-4b35-9a43-ad7179c4a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in text_columns.items():\n",
    "    \n",
    "    for var in [\"stemmed\", \"lemma\"]:\n",
    "        \n",
    "        # Initializing the CountVectorizer based on the min_df defined previously\n",
    "        globals()[\"bow_vectorizer_\" + key + \"_\" + var] = CountVectorizer(min_df=value)\n",
    "        \n",
    "        globals()[\"bow_\" + key + \"_\" + var] = globals()[\"bow_vectorizer_\" + key + \"_\" + var].fit_transform(df_data[key + \"_\" + var].astype(\"U\"))\n",
    "        globals()[\"df_bow_\" + key + \"_\" + var] = pd.DataFrame(globals()[\"bow_\" + key + \"_\" + var].toarray(),\n",
    "                                                              columns=globals()[\"bow_vectorizer_\" + key + \"_\" + var].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a4851-1478-4ff2-97a3-b30caaa69e7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Printing some resultants datasets</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6e723-77e7-4cf9-83f5-56317f93d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*120)\n",
    "print(\" >> product_name_stemmed\")\n",
    "display(df_bow_product_name_stemmed.head())\n",
    "print(\" >> product_name_lemma\")\n",
    "display(df_bow_product_name_lemma.head())\n",
    "print(\"\\n\")\n",
    "print(\"-\"*120)\n",
    "print(\" >> description_stemmed\")\n",
    "display(df_bow_description_stemmed.head())\n",
    "print(\" >> description_lemma\")\n",
    "display(df_bow_description_lemma.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd365a8-d37a-46f1-86f4-6ba225602c10",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.5.3. Term Frequency - TF-IDF</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdfb81-dfb2-4d74-a5b0-71dbce90d0d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to do a TF-IDF for each feature, considering the stemmed and lemma treatments</p>\n",
    "    <p>Let's initialize the TfidfVectorizer based on the min_df defined</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4044ad-29e2-4a17-a1b2-e0066f014a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in text_columns.items():\n",
    "    \n",
    "    for var in [\"stemmed\", \"lemma\"]:\n",
    "        \n",
    "        # Initializing the TfidfVectorizer based on the min_df defined previously\n",
    "        globals()[\"tfidf_vectorizer_\" + key + \"_\" + var] = TfidfVectorizer(min_df=value)\n",
    "        \n",
    "        globals()[\"tfidf_\" + key + \"_\" + var] = globals()[\"tfidf_vectorizer_\" + key + \"_\" + var].fit_transform(df_data[key + \"_\" + var].astype(\"U\"))\n",
    "        globals()[\"df_tfidf_\" + key + \"_\" + var] = pd.DataFrame(globals()[\"tfidf_\" + key + \"_\" + var].toarray(),\n",
    "                                                                columns=globals()[\"tfidf_vectorizer_\" + key + \"_\" + var].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14185e54-fe50-4558-b193-7622ffd78571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*120)\n",
    "print(\" >> product_name_stemmed\")\n",
    "display(df_tfidf_product_name_stemmed.head())\n",
    "print(\" >> product_name_lemma\")\n",
    "display(df_tfidf_product_name_lemma.head())\n",
    "print(\"\\n\")\n",
    "print(\"-\"*120)\n",
    "print(\" >> description_stemmed\")\n",
    "display(df_tfidf_description_stemmed.head())\n",
    "print(\" >> description_lemma\")\n",
    "display(df_tfidf_description_lemma.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad0cb9-4812-47cc-9c26-3b00a8980cf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Printing some resultants datasets</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203735b-c50b-4d55-bc66-f4f7ffb80de5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">5.5.4. Compare the results</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42480f-adb0-4fa4-b1c2-66dd8de2cd84",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's compare the words most frequents based on BoW and TI-IDF</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43afcaea-4ce2-4760-badc-0241c77fdd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, value in text_columns.items():\n",
    "    \n",
    "    for var in [\"stemmed\", \"lemma\"]:\n",
    "        \n",
    "        for type_of_vector in [\"bow\", \"tfidf\"]:\n",
    "            \n",
    "            if type_of_vector == \"bow\":\n",
    "                palette = \"flare\"\n",
    "                temp = \"BoW\"\n",
    "            else:\n",
    "                palette = \"crest\"\n",
    "                temp = \"TF-IDF\"\n",
    "        \n",
    "             # Plottint the results\n",
    "            most_frequent_words = (globals()[\"df_\" + type_of_vector + \"_\" + col + \"_\" + var].sum(axis=0)).sort_values(ascending=False).head(30)\n",
    "\n",
    "            fig = plt.figure(figsize=(15, 5))\n",
    "            plot = sns.barplot(x=most_frequent_words.index, y=most_frequent_words, palette=palette)\n",
    "            plot.set_xticklabels(labels=most_frequent_words.index, rotation=70, size=12,\n",
    "                                     horizontalalignment=\"right\")\n",
    "            plt.ylabel(\"count\", size=12)\n",
    "            plt.xlabel(\"words\", size=12)\n",
    "            plt.title(\"The 30 words most frequents words in \\\"\" + col + \"\\\" - \\\"\" + var + \"\\\"\\n\" + temp, size=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd3241-e4e7-440b-81ce-75ec6c3ce5da",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">5.6. Topic modeling with LDA</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632d603-413f-4f60-922f-b3a065171a59",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to model the topic for each features through Latent Dirichlet Allocation - LDA</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236003ff-5045-4244-aede-88178ed2c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = df_data[\"category_1\"].nunique()\n",
    "no_top_words = 10\n",
    "\n",
    "for col, value in text_columns.items():\n",
    "    \n",
    "    for var in [\"stemmed\", \"lemma\"]:\n",
    "        \n",
    "        for type_of_vector in [\"bow\", \"tfidf\"]:\n",
    "    \n",
    "            globals()[\"lda_\" + col + \"_\" + var + \"_\" + type_of_vector] = LatentDirichletAllocation(n_components=n_components)\n",
    "            globals()[\"df_lda_\" + col + \"_\" + var + \"_\" + type_of_vector] = \\\n",
    "                globals()[\"lda_\" + col + \"_\" + var + \"_\" + type_of_vector].fit_transform(globals()[\"df_\" + type_of_vector + \"_\" + col + \"_\" + var])\n",
    "            \n",
    "            tf_feature_names = globals()[type_of_vector + \"_vectorizer_\" + col + \"_\" + var].get_feature_names_out()\n",
    "            \n",
    "            \n",
    "            print(\"-\"*80)\n",
    "            print(\" >>\", col.upper(), \"-\", var.upper(), \"-\", type_of_vector.upper())\n",
    "            display_topics(globals()[\"lda_\" + col + \"_\" + var + \"_\" + type_of_vector],\n",
    "                           tf_feature_names, no_top_words)\n",
    "            print(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ebf5c-58fe-4c02-a921-a9a6915b3e13",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">5.7. Concatenating resulting dataset</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e30b6-cb62-4e01-801e-88553e941b01",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>From this point, we are going to use <b>the feautures treated with Lemmatization</b></p>\n",
    "    <p>First of all, we are going to add a prefix on all column based on the feature, just in case we need to identify them later</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a74b8a-5a85-43d9-87ad-3e097bf040b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prefix = {\n",
    "    \"product_name\": \"pn_\",\n",
    "    \"product_category_tree\": \"pct_\",\n",
    "    \"description\": \"d_\",\n",
    "    \"brand\": \"b_\",\n",
    "    \"product_specifications\": \"ps_\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9dbfa-33ad-4cd8-9a87-6970b65708eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_of_vector in [\"bow\", \"tfidf\"]:\n",
    "\n",
    "    for col, prefix in dataset_prefix.items():\n",
    "                \n",
    "        globals()[\"df_\" + type_of_vector + \"_\" + col + \"_lemma\"] = globals()[\"df_\" + type_of_vector + \"_\" + col + \"_lemma\"].add_prefix(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aebe41-ebf3-420e-9439-5d08af0352f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_of_vector in [\"bow\", \"tfidf\"]:\n",
    "\n",
    "    for col, prefix in dataset_prefix.items():\n",
    "        \n",
    "        for var in [\"stemmed\", \"lemma\"]:\n",
    "                \n",
    "            globals()[\"df_\" + type_of_vector + \"_\" + col + \"_\" + var] = globals()[\"df_\" + type_of_vector + \"_\" + col + \"_\" + var].add_prefix(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb40c09-f526-4850-91b3-6b1f5cf527e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Concatenating the dataset</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d96df-7218-4256-8e22-451a2029ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stemmed_BoW = pd.concat([df_bow_product_name_stemmed, df_bow_product_category_tree_stemmed, df_bow_description_stemmed,\n",
    "                          df_bow_brand_stemmed, df_bow_product_specifications_stemmed], axis=1)\n",
    "\n",
    "df_stemmed_tfidf = pd.concat([df_tfidf_product_name_stemmed, df_tfidf_product_category_tree_stemmed, df_tfidf_description_stemmed,\n",
    "                          df_tfidf_brand_stemmed, df_tfidf_product_specifications_stemmed], axis=1)\n",
    "\n",
    "df_lemma_BoW = pd.concat([df_bow_product_name_lemma, df_bow_product_category_tree_lemma, df_bow_description_lemma,\n",
    "                          df_bow_brand_lemma, df_bow_product_specifications_lemma], axis=1)\n",
    "\n",
    "df_lemma_tfidf = pd.concat([df_tfidf_product_name_lemma, df_tfidf_product_category_tree_lemma, df_tfidf_description_lemma,\n",
    "                          df_tfidf_brand_lemma, df_tfidf_product_specifications_lemma], axis=1)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\" >> Stemmed\")\n",
    "print(\"df_stemmed_BoW shape:\\t\", df_stemmed_BoW.shape)\n",
    "print(\"df_stemmed_tfidf shape:\\t\", df_stemmed_tfidf.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\" >> Lemma\")\n",
    "print(\"df_lemma_BoW shape:\\t\", df_lemma_BoW.shape)\n",
    "print(\"df_lemma_tfidf shape:\\t\", df_lemma_tfidf.shape)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c9da8-ae27-4417-a2e2-285a367e2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stemmed_BoW.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1a0e4-2480-4899-948a-9453b9d33209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stemmed_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e64316-4d72-41cb-93f7-a75825afe203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_BoW.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ad3e0-d9b4-4fb9-b8b1-02eeb3df7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae710f1c-30b8-43db-bfd3-e1e4273460c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Now, we have 4 dataset based on text (BoW) that we are going to combine with images (BoVW) to clasify them (images)<br>\n",
    "    Next, the list of dataset so far.</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li><b>df_stemmed_BoW</b>:&nbsp;&nbsp;&nbsp;Stemming the tokens + Bag of Word (BoW)</li>\n",
    "        <li><b>df_stemmed_tfidf</b>:&nbsp;&nbsp;&nbsp;&nbsp;Stemming the tokens + Term Frequency (TF-IDF)</li>\n",
    "        <li><b>df_lemma_BoW</b>:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lemmatization the tokens + Bag of Word (BoW)</li>\n",
    "        <li><b>df_lemma_tfidf</b>:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lemmatization the tokens + Term Frequency (TF-IDF)</li>\n",
    "    </ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6b2f6-ff2b-4611-9e03-90d8522ad885",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">6. Pre-processing Images</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc6408-8fd8-464c-822e-01ae7d3c7345",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">6.1. Analyzing images</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7038917-5b80-4505-951f-3319bbfb9d4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's take a look at some images before dealing with them</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba5486a-a6d9-47ab-914f-77ef2a2141e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = 1, 10\n",
    "\n",
    "# Grpuping data by category\n",
    "df_groupby = df_data.groupby(\"category_1\")\n",
    "\n",
    "for category, sub_df in df_groupby:\n",
    "    \n",
    "    #  list to save images size\n",
    "    image_name, height_size, width_size = [[] for i in range(3)]\n",
    "    \n",
    "    # Filtering random images by each category\n",
    "    images_index_by_category = sub_df.sample(10).index\n",
    "    \n",
    "    # Initializing each figure/plot\n",
    "    fig = plt.figure(figsize=(15, 2))\n",
    "    plt.suptitle(category, fontweight=\"bold\")\n",
    "    \n",
    "    for i, image_index in enumerate(images_index_by_category, 1):\n",
    "        \n",
    "        # Identifying an image\n",
    "        image = df_data[\"image\"].loc[image_index]\n",
    "        image_name.append(image)\n",
    "        \n",
    "        # Reading the image attributes\n",
    "        img = cv2.imread(ORIGINAL_IMAGES_PATH + image, cv2.IMREAD_UNCHANGED)\n",
    "        height_size.append(img.shape[0])\n",
    "        width_size.append(img.shape[1])\n",
    "        \n",
    "        # Reading a specific image based on index\n",
    "        image = mpimg.imread(ORIGINAL_IMAGES_PATH + image)\n",
    "        \n",
    "        # Plotting imaga in one row based on category\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i)        \n",
    "        ax.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    df_images = pd.DataFrame({\n",
    "        \"Image\": image_name,\n",
    "        \"Width\": width_size,\n",
    "        \"Height\": height_size\n",
    "    })\n",
    "    \n",
    "    plt.show()\n",
    "    display(df_images)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd884db-9aa3-4b0b-8ce3-fe93b2905721",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this point, we can conclude </p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>It seems that images are good categorized based on the 1 level of the tree of categories</li>\n",
    "        <li>Most of images are a big size</li>\n",
    "    </ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc537b3e-88a8-4ce0-bc60-4039634af304",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">6.2. Processing images</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe502c-8616-42ce-a034-799c46b755fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We are going to process images as follows:</p>\n",
    "    <ol>\n",
    "        <li>Size reduction</li>\n",
    "        <li>Adjusting contrast and brightness</li>\n",
    "        <li>Transform to gray</li>\n",
    "        <li>Noise reduction</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6790ef4-8d91-41e6-a762-24d4b8cc904d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.2.1. Size reduction</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7351432-ca8f-453b-abe2-d305cce1cbc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's reduce images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650382b2-ff2e-4cb0-9144-be1db3734fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"image\"].apply(lambda x: thumbnail_image(x, basewidth=224, path=ORIGINAL_IMAGES_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36019f-9c41-4bfb-9a0f-a6b289a74e07",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at the results</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bed156-d253-4a4d-aabd-8d146ef92172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images[[\"new_width\", \"new_height\"]] = df_images[\"Image\"].apply(lambda x: image_size(x, ORIGINAL_IMAGES_PATH + \"thumbnails/\")).to_list()\n",
    "df_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5897dc9-fa8b-4cb7-8e9b-eb59b7322b06",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>Now, we get the image reduced</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7a5ce-35e7-4cda-9fd3-703c1966c08b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.2.2. Adjusting contrast and brightness</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676566d7-a5a3-404e-86c9-3905519748fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to use the thumbnails created</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05775544-54c3-416a-a6fa-58ccab32890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"image\"].apply(lambda x: contrast_and_brightness(x, path=THUMBNAILS_IMAGES_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d66a8d-faab-4a5c-ba81-598d1c4074f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at the results</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b521a31-66df-4456-8a93-fe0af94417ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_and_histogram(\"0ec47240feda42c63e42f1e9cee60f7a.jpg\", \n",
    "                        ORIGINAL_IMAGES_PATH, CB_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffb047-8c63-497c-983a-c0d22d4a8c05",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.2.3. Gray images</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801e56b-a4a2-48cc-9984-d502850cf527",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>To transform images to gray escals, we are going to use the image with contrast and brightness modified</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1beb61a-01a8-4b6d-baa9-ef2810a6e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"image\"].apply(lambda x: gray_image(x, CB_IMAGES_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a170ab8-9f85-4d26-aa98-0ee28d10052a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at the results</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851b915-4d9f-498e-a767-c312f3ee3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread(ORIGINAL_IMAGES_PATH + \"0ec47240feda42c63e42f1e9cee60f7a.jpg\")\n",
    "gray_image = cv2.imread(GRAY_IMAGES_PATH + \"0ec47240feda42c63e42f1e9cee60f7a.jpg\")\n",
    "\n",
    "# Initializing each figure/plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5)) \n",
    "\n",
    "ax1.imshow(original_image)\n",
    "ax1.set_title(\"Image with contrast and brightness modified\",\n",
    "              fontsize=14, fontweight=\"bold\")\n",
    "ax1.grid(None)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.imshow(gray_image)\n",
    "ax2.set_title(\"Gray image\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.grid(None)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a98196-f72a-4cc2-a8a9-348a092f5a57",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.2.4. Noise reduction</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839f340-04da-4a2c-b487-54d29edf0de2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to use the gray images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8899ea-1140-4f56-b5da-3af9d0746ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"image\"].apply(lambda x: noise_reduction(x, GRAY_IMAGES_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fc82e-d297-4129-9524-98b13b8bf521",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at the results</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52a4f6-80bc-4101-bc5e-e842093f7e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_image = cv2.imread(GRAY_IMAGES_PATH + \"0ec47240feda42c63e42f1e9cee60f7a.jpg\")\n",
    "image_with_noise_reduced = cv2.imread(NR_IMAGES_PATH + \"0ec47240feda42c63e42f1e9cee60f7a.jpg\")\n",
    "\n",
    "# Initializing each figure/plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5)) \n",
    "\n",
    "ax1.imshow(gray_image)\n",
    "ax1.set_title(\"Gray image\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.grid(None)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.imshow(image_with_noise_reduced)\n",
    "ax2.set_title(\"Image with noise reduced\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.grid(None)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c68f9-0a71-46fe-892f-14c84d9151c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">6.3. SIFT and ORB Visualizations</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3872298c-1c7f-420e-aec8-14e5c9cef0e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We are going to select two images in same category (\"Watches\") to see the algorithms on them</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59b127-4ca1-455b-8bc2-fb7967584570",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_a = cv2.imread(NR_IMAGES_PATH + \"9924fba9b2a738e5a141995952e73104.jpg\")\n",
    "image_b = cv2.imread(NR_IMAGES_PATH + \"29b1ca231e10d5269516b80bf9d0dffc.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f776ab-1968-4df5-b994-398b52fb1e02",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's plot the images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b6e19-9ca2-455e-9c49-bc1a7aafe19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(image_a, image_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8a17e-47ce-47be-9df7-1358c4eac1a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.3.1. SIFT - Scale Invariant Feature Transformation </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287f70e-44f6-4df5-aac3-11df9255b443",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's detect key points and descriptors</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997c700-b605-48b6-860b-ff2a59c491c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "\n",
    "key_points_a_sift, descriptors_a_sift = sift.detectAndCompute(image_a, None)\n",
    "key_points_b_sift, descriptors_b_sift = sift.detectAndCompute(image_b, None)\n",
    "\n",
    "image_a_key_points_sift = cv2.drawKeypoints(image_a, key_points_a_sift, None)\n",
    "image_b_key_points_sift = cv2.drawKeypoints(image_b, key_points_b_sift, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22234211-7264-48c3-91d6-6421939e0b1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's plot the images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3f869-b11c-411c-993a-6331963d8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(image_a_key_points_sift, image_b_key_points_sift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d9e2e-6b24-4261-bc0d-ee8d70684ba0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's match the images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d394ac7-055c-4f17-b7b7-a5805afbf3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature matching\n",
    "bf_macher_sift = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "matches_sift = bf_macher_sift.match(descriptors_a_sift, descriptors_b_sift)\n",
    "matches_sift = sorted(matches_sift, key=lambda x: x.distance)\n",
    "image_3_sift = cv2.drawMatches(image_a, key_points_a_sift, image_b, key_points_b_sift,\n",
    "                               matches_sift[:50], None, flags=2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image_3_sift)\n",
    "plt.grid(None)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Matching images\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5868a-c4d0-4b89-86fc-af8f3d538ef2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.3.2. ORB - Oriented Fast and Rotated BRIEF</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d78cf4-d172-4afa-b707-50f3cf3aa5c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's detect key points and descriptors</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed91a9d-b07d-4ac5-a93a-d2b61479e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()\n",
    "\n",
    "key_points_a_orb, descriptors_a_orb = orb.detectAndCompute(image_a, None)\n",
    "key_points_b_orb, descriptors_b_orb = orb.detectAndCompute(image_b, None)\n",
    "\n",
    "image_a_key_points_orb = cv2.drawKeypoints(image_a, key_points_a_orb, None)\n",
    "image_b_key_points_orb = cv2.drawKeypoints(image_b, key_points_b_orb, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14efba18-da50-4b0a-80e4-22ed857f218b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's plot the images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5281c9e-e4c2-40ac-b949-82da3ac59177",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(image_a_key_points_orb, image_b_key_points_orb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b955d90-7ce3-4b21-b6da-823414e91990",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's match the images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eacaa7c-ce9b-4c03-8875-6368f0cd7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature matching\n",
    "bf_macher_orb = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "matches_orb = bf_macher_orb.match(descriptors_a_orb, descriptors_b_orb)\n",
    "matches_orb = sorted(matches_orb, key=lambda x: x.distance)\n",
    "image_3_orb = cv2.drawMatches(image_a, key_points_a_orb, image_b, key_points_b_orb,\n",
    "                              matches_orb[:50], None, flags=2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image_3_orb)\n",
    "plt.grid(None)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Matching images - ORB\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac2c48-78d4-4fb9-8c69-90d441958ee7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; font-size:16px;\">6.3.3. Comparing SIFT / ORB</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a303bd-f9a5-45f9-8448-c7e058f736ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's plot the images</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997bc5ab-bdbc-48c6-855e-c38bf0d412a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(image_a_key_points_sift, image_a_key_points_orb,\n",
    "               title_a=\"SIFT descriptors\", title_b=\"ORB descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a65ae9-24dc-49ce-a131-208887b8ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_images(image_b_key_points_sift, image_b_key_points_orb,\n",
    "               title_a=\"SIFT descriptors\", title_b=\"ORB descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f638447-d36a-40ad-a101-c432b9d56c20",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">6.4. Image Vectorization</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b0aee-8c46-462b-a442-7ace575527fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.4.1. Features detection by image</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fa9e7-cd32-49d1-9650-72ff0f1f646c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We are going to detect the images descriptors through SIFT and ORB</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666c067-8416-45f4-97d6-72ee76b9efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "orb = cv2.ORB_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e64eaf-cebb-42a9-82bd-68e12d91d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = {\n",
    "    \"sift\": sift,\n",
    "    \"orb\": orb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00884fd-68e3-41a6-bb1a-634596a9902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    globals()[key + \"_desc_by_image\"], globals()[key + \"_desc_all\"] = get_descriptors(df_data[\"image\"],\n",
    "                                                                                       NR_IMAGES_PATH,\n",
    "                                                                                       value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24fd34-81ee-45b5-ae77-592084031726",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.4.2. Clustering to build images features</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223ee3a-74b9-4b62-9306-1c714f5ee379",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to use MiniBatchKMeans to build image features</p>\n",
    "    <p>Determination number of clusters and batch size<br># of cluster is fixed as sqrt of # descriptors</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f8d3b-ae4c-40b9-8487-e81b3a483e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    globals()[\"k_\" + key] = int(round(np.sqrt(len(globals()[key + \"_desc_all\"])), 0))\n",
    "    globals()[\"batch_size_\" + key] = df_data[\"image\"].shape[0] * 3\n",
    "    \n",
    "    print(\"-\"*25)\n",
    "    print(\" >>\", key.upper())\n",
    "    \n",
    "    print(\"Number of clusters:\", globals()[\"k_\" + key])\n",
    "    print(\"Batch size:\", globals()[\"batch_size_\" + key])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940d54b-fec5-4a78-8be4-594eade00b80",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Initialize the clusterer with n_clusters=k value and a random generator seed of 10 for reproducibility.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff932323-2fd6-4152-9aeb-2c50693f4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "\n",
    "    globals()[key + \"_kmeans\"] = MiniBatchKMeans(n_clusters=globals()[\"k_\" + key], init=\"k-means++\", \n",
    "                                                 max_iter=1000, batch_size=globals()[\"batch_size_\" + key],\n",
    "                                                 random_state=10, init_size=3*globals()[\"k_\" + key])\n",
    "\n",
    "    globals()[key + \"_kmeans\"].fit(globals()[key + \"_desc_all\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc7eeec-7b60-494a-8373-1e19ce97f819",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.4.3. Creation of image features</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501ce83-b69a-4472-be61-0c6a14c559dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    print(\"-\"*10)\n",
    "    print(\" >>\", key.upper())\n",
    "    \n",
    "    globals()[key + \"_img_features\"], globals()[key + \"_img_features_weighed\"] = \\\n",
    "        build_features(globals()[key + \"_kmeans\"], globals()[key + \"_desc_by_image\"])\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406eb023-8d1f-48e7-a3d1-c18daf7805cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    globals()[\"df_\" + key + \"_img_features\"] = pd.DataFrame(globals()[key + \"_img_features\"])\n",
    "    globals()[\"df_\" + key + \"_img_features_weighed\"] = pd.DataFrame(globals()[key + \"_img_features_weighed\"])\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    ax = plt.subplot(311)\n",
    "    \n",
    "    ax.set_title(\"Labels histogram - \" + key.upper(), size=20, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Visual words\", size=14)\n",
    "    ax.set_ylabel(\"Frequency\", size=14)\n",
    "    \n",
    "    ax.plot(globals()[\"df_\" + key + \"_img_features\"][1].ravel())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\" >>\", key.upper(), \"(weighed)\")\n",
    "    display(globals()[\"df_\" + key + \"_img_features_weighed\"].head())\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19931a6-e87d-43b4-9003-df21c166ff65",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to add a prefix on all column based on the feature, just in case we need to identify them later</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3c554-ba4d-4c0a-a7fd-efee71152e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sift_img_features = df_sift_img_features.add_prefix(\"s_\")\n",
    "df_sift_img_features_weighed = df_sift_img_features_weighed.add_prefix(\"sw_\")\n",
    "\n",
    "df_orb_img_features = df_orb_img_features.add_prefix(\"o_\")\n",
    "df_orb_img_features_weighed = df_orb_img_features_weighed.add_prefix(\"ow_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587374b-3671-4e8d-8e96-311ad99e2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sift_img_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aba624-cc07-4ef6-8047-b8baf7ccbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orb_img_features_weighed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ae436-45cd-4e65-a474-cefb8a389fa0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this points, we have the features based on the images - BoVW.<br> In fact, we have 4 dataset as follows</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li><b>df_sift_img_features</b>: BoVW based on SIFT algorithm</li>\n",
    "        <li><b>df_sift_img_features_weighed</b>: BoVW based on SIFT algorithm and weighed based on the number of descriptors of each image</li>\n",
    "        <li><b>df_orb_img_features</b>: BoVW based on ORB algorithm</li>\n",
    "        <li><b>df_orb_img_features_weighed</b>: BoVW based on ORB algorithm and weighed based on the number of descriptors of each image</li>\n",
    "    </ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37571202-1c58-400e-bc96-48e17ef9cbb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">6.5. BoVW visualization without clusterization</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578badcc-a9aa-4801-8de9-f1d5ee17afdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.5.1. PCA dimension reduction</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2760af9-cdeb-43e0-b1a7-9efd017e3455",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We are going to reduce the features dimension through PCA, keeping a high level of explained variance</p>\n",
    "    <p>But first, let's identify the minimum and maximun value in the dataset.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d586d9c-5f44-4e00-ae91-7176226426d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    minimun = globals()[\"df_\" + key + \"_img_features_weighed\"].apply(np.min).min()\n",
    "    maximun = globals()[\"df_\" + key + \"_img_features_weighed\"].apply(np.max).max()\n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    print(\" >>\", key.upper())\n",
    "    print(\"The minimun value is: \", round(minimun, 3))\n",
    "    print(\"The maximun value is: \", round(maximun, 3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c379980-aec0-4dca-ae70-4cf9d8f4c933",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>All data is in the same range</li>\n",
    "        <li>SIFT: the minimun and maximun value are between 0 and 0.58 respectively</li>\n",
    "        <li>ORB: the minimun and maximun value are between 0 and 1 respectively</li>\n",
    "    </ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc703d3-558c-4f0d-9ed3-3fb76ed2916f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to reduce the features keeping 80% of explained variance</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66be64-ef64-4977-83bb-a457c9c886c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    print(\" >>\", key.upper())\n",
    "    print(\"Dataset dimensions before PCA reduction: \", globals()[\"df_\" + key + \"_img_features_weighed\"].shape)\n",
    "    \n",
    "    globals()[\"pca_\" + key] = PCA(n_components=0.80)\n",
    "    globals()[\"df_\" + key + \"_img_features_pca\"] = globals()[\"pca_\" + key].fit_transform(globals()[\"df_\" + key + \"_img_features_weighed\"])\n",
    "    \n",
    "    print(\"Dataset dimensions after PCA reduction: \", globals()[\"df_\" + key + \"_img_features_pca\"].shape)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c54990-4b51-4dea-bee6-d552c7b664d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    axvline_value = globals()[\"df_\" + key + \"_img_features_pca\"].shape[1]\n",
    "    \n",
    "    globals()[\"scree_\" + key] = globals()[\"pca_\" + key].explained_variance_ratio_*100\n",
    "    \n",
    "    fig = plt.subplots(figsize=(8, 5))\n",
    "    plt.plot(np.arange(len(globals()[\"scree_\" + key]))+1,\n",
    "             globals()[\"scree_\" + key].cumsum())\n",
    "    \n",
    "    plt.xlabel(\"Number of principal components\", size=12)\n",
    "    plt.ylabel(\"% of inertia\", size=12)\n",
    "    \n",
    "    plt.axhline(80, lw=1, c=\"red\")\n",
    "    plt.text(1, 81, \"80%\", c=\"red\")\n",
    "    \n",
    "    plt.axvline(axvline_value, lw=1, c=\"red\")\n",
    "    plt.text(axvline_value - 6, 8, axvline_value, c=\"red\")\n",
    "    \n",
    "    plt.title(\"Scree of eigenvalues - \" + key.upper(), size=18, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff320f28-868a-4616-97b4-35986c0bfc03",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this point, we have reduced the data as follows:</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>SIFT: From (1050, 546) to (1050, 131)</li>\n",
    "        <li>ORB: From (1036, 567) to (1036, 109)</li>\n",
    "    </ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434b944-dc25-48d7-9775-7b644c419ce8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">6.5.2. T-SNE dimension reduction</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d85212-1b6b-4f50-9de1-cf6431e5bd03",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's reduce the dimension to 2 T-SNE components to visualize in 2D</p>\n",
    "    <p>At the same time, we are going to add the 1 level of tree category to visualize data based on this feature</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba53459-4dc9-498e-b208-192ed39a1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    globals()[\"tsne_\" + key] = TSNE(n_components=2, n_iter=2000, learning_rate=\"auto\",\n",
    "                                    init=\"random\", random_state=10)\n",
    "    globals()[\"X_tsne_\" + key] = globals()[\"tsne_\" + key].fit_transform(globals()[\"df_\" + key + \"_img_features_pca\"])\n",
    "    \n",
    "    globals()[\"df_tsne_\" + key] = pd.DataFrame(globals()[\"X_tsne_\" + key][:, 0:2], columns=[\"tsne_1\", \"tsne_2\"])\n",
    "    globals()[\"df_tsne_\" + key][\"category\"] = df_data[\"category_1\"]\n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    print(\" >>\", key.upper())\n",
    "    print(\"Dataset dimensions before T-SNE reduction: \", globals()[\"df_\" + key + \"_img_features_pca\"].shape)\n",
    "    print(\"Dataset dimensions after T-SNE reduction: \", globals()[\"df_tsne_\" + key].shape)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7e441-ee4f-495a-beb4-0dfcb1bfd390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in detectors.items():\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    sns.scatterplot(x=\"tsne_1\", y=\"tsne_2\", hue=\"category\", \n",
    "                    data=globals()[\"df_tsne_\" + key], legend=\"brief\",\n",
    "                    palette=sns.color_palette(\"tab10\", n_colors=7),\n",
    "                    s=50, alpha=0.6)\n",
    "    \n",
    "    plt.title(\"T-SNE based on 1 level of categories - \" + key.upper(), fontsize=18,\n",
    "              pad=10, fontweight=\"bold\")\n",
    "    plt.xlabel(\"tsne_1\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"tsne_2\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc=\"upper left\", prop={\"size\": 12},\n",
    "              title=\"Categories\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d17bd-6962-4286-9390-be3d3d02b1df",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>We can see that it is not clear the data</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805888aa-e15f-436c-b27e-b275eb879861",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">7. Clusterization</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399b9f7-52ed-4247-aa67-ad5a5bd53a09",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">7.1. Concatenation of features (texts and images)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5dbaa-336b-4d98-bffe-b7f8ac45b271",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>From the original dataset, we are going to keep the following values</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li>retail_price</li>\n",
    "    </ul>\n",
    "    <p>We are going to concatenate data based on the following dataset</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li><b>Features based on text data</b></li>\n",
    "        <ul style=\"list-style-type: disc;\">\n",
    "            <li><b>df_stemmed_BoW</b>: Stemming the tokens + Bag of Word (BoW)</li>\n",
    "            <li><b>df_stemmed_tfidf</b>: Stemming the tokens + Term Frequency (TF-IDF)</li>\n",
    "            <li><b>df_lemma_BoW</b>: Lemmatization the tokens + Bag of Word (BoW)</li>\n",
    "            <li><b>df_lemma_tfidf</b>: Lemmatization the tokens + Term Frequency (TF-IDF)</li>\n",
    "        </ul>\n",
    "        <li><b>Features based on image data</b></li>\n",
    "        <ul style=\"list-style-type: disc;\">\n",
    "            <li><b>df_sift_img_features</b>: BoVW based on SIFT algorithm</li>\n",
    "            <li><b>df_sift_img_features_weighed</b>: BoVW based on SIFT algorithm and weighed based on the number of descriptors of each image</li>\n",
    "            <li><b>df_orb_img_features</b>: BoVW based on ORB algorithm</li>\n",
    "            <li><b>df_orb_img_features_weighed</b>: BoVW based on ORB algorithm and weighed based on the number of descriptors of each image</li>\n",
    "        </ul> \n",
    "    </ul>  \n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a6fff-c4b5-42e1-8f96-9ffc19d3f071",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with <b>only features based on texts</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c270b8a-b5ee-4fa0-9226-dd4b57181ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on Bag of words\n",
    "bow_stemmed = df_stemmed_BoW.copy()\n",
    "bow_lemma = df_lemma_BoW.copy()\n",
    "\n",
    "# based on TF-IDF\n",
    "tfidf_stemmed = df_stemmed_tfidf.copy()\n",
    "tfidf_lemma = df_lemma_tfidf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003830ce-0494-4ccb-b095-2130a4983784",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with <b>features based on texts  + price</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9529f2d-8d5d-4b0a-bd12-aea283714fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on Bag of words + price\n",
    "bow_stemmed_price = pd.merge(df_data[[\"retail_price_log2\"]], bow_stemmed, left_index=True, right_index=True)\n",
    "bow_lemma_price = pd.merge(df_data[[\"retail_price_log2\"]], bow_lemma, left_index=True, right_index=True)\n",
    "\n",
    "# based on TF-IDF + price\n",
    "tfidf_stemmed_price = pd.merge(df_data[[\"retail_price_log2\"]], tfidf_stemmed, left_index=True, right_index=True)\n",
    "tfidf_lemma_price = pd.merge(df_data[[\"retail_price_log2\"]], tfidf_lemma, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad77454-da1d-4803-ab8a-662ba82352ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with <b>only features based on images</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a36eb-f3ba-4935-8855-76a84a5c890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm\n",
    "sift = df_sift_img_features.copy()\n",
    "sift_weighed = df_sift_img_features_weighed.copy()\n",
    "\n",
    "# based on ORB algorithm\n",
    "orb = df_orb_img_features.copy()\n",
    "orb_weighed = df_orb_img_features_weighed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282d380-56a9-4fd9-a440-24671701861f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + price</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ca2a3-0b6b-441c-b716-928d8070fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + price\n",
    "sift_price = pd.merge(df_data[[\"retail_price_log2\"]], sift, left_index=True, right_index=True)\n",
    "sift_weighed_price = pd.merge(df_data[[\"retail_price_log2\"]], sift_weighed, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + price\n",
    "orb_price = pd.merge(df_data[[\"retail_price_log2\"]], orb, left_index=True, right_index=True)\n",
    "orb_weighed_price = pd.merge(df_data[[\"retail_price_log2\"]], orb_weighed, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae8804-5d50-4c03-8f6b-42bcbf8af302",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + BoW stemmed</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02310d6c-b0af-4695-b786-68a4286c57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + BoW stemmed\n",
    "sift_bow_stemmed = pd.merge(sift, df_stemmed_BoW, left_index=True, right_index=True)\n",
    "sift_weighed_bow_stemmed = pd.merge(sift_weighed, df_stemmed_BoW, left_index=True, right_index=True)\n",
    "# based on ORB algorithm + BoW stemmed\n",
    "orb_bow_stemmed = pd.merge(orb, df_stemmed_BoW, left_index=True, right_index=True)\n",
    "orb_weighed_bow_stemmed = pd.merge(orb_weighed, df_stemmed_BoW, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57516b2c-8fcc-478f-9606-1800fddffe4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + BoW lemma</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b8c18-634c-4336-841d-56673523c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + BoW lemma\n",
    "sift_bow_lemma = pd.merge(sift, df_lemma_BoW, left_index=True, right_index=True)\n",
    "sift_weighed_bow_lemma = pd.merge(sift_weighed, df_lemma_BoW, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + BoW lemma\n",
    "orb_bow_lemma = pd.merge(orb, df_lemma_BoW, left_index=True, right_index=True)\n",
    "orb_weighed_bow_lemma = pd.merge(orb_weighed, df_lemma_BoW, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e28378-3c70-48e2-8ceb-b2a24119115f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + TF-IDF stemmed</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78c1dc-fce1-4305-953d-9886291f1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + TF-IDF stemmed\n",
    "sift_tfidf_stemmed = pd.merge(sift, df_stemmed_tfidf, left_index=True, right_index=True)\n",
    "sift_weighed_tfidf_stemmed = pd.merge(sift_weighed, df_stemmed_tfidf, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + TF-IDF stemmed\n",
    "orb_tfidf_stemmed = pd.merge(orb, df_stemmed_tfidf, left_index=True, right_index=True)\n",
    "orb_weighed_tfidf_stemmed = pd.merge(orb_weighed, df_stemmed_tfidf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3d5bf-b882-4629-bbdc-93b8e3c4be12",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + TF-IDF lemma</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6978f-1b22-430d-8437-c747035b2e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + TF-IDF lemma\n",
    "sift_tfidf_lemma = pd.merge(sift, df_lemma_tfidf, left_index=True, right_index=True)\n",
    "sift_weighed_tfidf_lemma =pd.merge(sift_weighed, df_lemma_tfidf, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + TF-IDF lemma\n",
    "orb_tfidf_lemma = pd.merge(orb, df_lemma_tfidf, left_index=True, right_index=True)\n",
    "orb_weighed_tfidf_lemma = pd.merge(orb_weighed, df_lemma_tfidf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088c527-46d2-4d0e-8912-e0c44e4c6018",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + price + BoW stemmed</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67181c58-dc07-4991-911b-3062cb9f8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + price + BoW stemmed\n",
    "sift_price_bow_stemmed = pd.merge(sift_price, df_stemmed_BoW, left_index=True, right_index=True)\n",
    "sift_weighed_price_bow_stemmed = pd.merge(sift_weighed_price, df_stemmed_BoW, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + price + BoW stemmed\n",
    "orb_price_bow_stemmed = pd.merge(orb_price, df_stemmed_BoW, left_index=True, right_index=True)\n",
    "orb_weighed_price_bow_stemmed = pd.merge(orb_weighed_price, df_stemmed_BoW, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d7163-eb47-4278-9ca0-4cea37cb7626",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + price + BoW lemma</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ef389-6c53-49d4-95ca-70b4e0431d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + price + BoW lemma\n",
    "sift_price_bow_lemma = pd.merge(sift_price, df_lemma_BoW, left_index=True, right_index=True)\n",
    "sift_weighed_price_bow_lemma = pd.merge(sift_weighed_price, df_lemma_BoW, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + price + BoW lemma\n",
    "orb_price_bow_lemma = pd.merge(orb_price, df_lemma_BoW, left_index=True, right_index=True)\n",
    "orb_weighed_price_bow_lemma = pd.merge(orb_weighed_price, df_lemma_BoW, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a60b3e-c8ef-4106-a17d-ec2ff2fb6e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + price + TF-IDF stemmed</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757bc74-2160-47d0-ad3e-a2626524cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + price + TF-IDF stemmed\n",
    "sift_price_tfidf_stemmed = pd.merge(sift_price, df_stemmed_tfidf, left_index=True, right_index=True)\n",
    "sift_weighed_price_tfidf_stemmed = pd.merge(sift_weighed_price, df_stemmed_tfidf, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + price + TF-IDF stemmed\n",
    "orb_price_tfidf_stemmed = pd.merge(orb_price, df_stemmed_tfidf, left_index=True, right_index=True)\n",
    "orb_weighed_price_tfidf_stemmed = pd.merge(orb_weighed_price, df_stemmed_tfidf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257739e7-9c91-4a2f-bc91-206662ee53df",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Defining dataset with features <b>based on images + price + TF-IDF lemma</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405fe5af-193c-4bd3-972e-feec03a433b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on SIFT algorithm + price + TF-IDF lemma\n",
    "sift_price_tfidf_lemma = pd.merge(sift_price, df_lemma_tfidf, left_index=True, right_index=True)\n",
    "sift_weighed_price_tfidf_lemma = pd.merge(sift_weighed_price, df_lemma_tfidf, left_index=True, right_index=True)\n",
    "\n",
    "# based on ORB algorithm + price + TF-IDF lemma\n",
    "orb_price_tfidf_lemma = pd.merge(orb_price, df_lemma_tfidf, left_index=True, right_index=True)\n",
    "orb_weighed_price_tfidf_lemma = pd.merge(orb_weighed_price, df_lemma_tfidf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ed3de-6611-4275-adad-bd64c1f36a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>List of datset (combinated) to work on them</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25670941-d3e2-4dff-a3f4-5d8237ce19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    bow_stemmed, bow_lemma,\n",
    "    tfidf_stemmed, tfidf_lemma,\n",
    "    bow_stemmed_price, bow_lemma_price,\n",
    "    tfidf_stemmed_price, tfidf_lemma_price,\n",
    "    sift, orb, \n",
    "    sift_weighed, orb_weighed,\n",
    "    sift_price, orb_price,\n",
    "    sift_weighed_price, orb_weighed_price,\n",
    "    sift_bow_stemmed, orb_bow_stemmed,\n",
    "    sift_weighed_bow_stemmed, orb_weighed_bow_stemmed,\n",
    "    sift_bow_lemma, orb_bow_lemma,\n",
    "    sift_weighed_bow_lemma, orb_weighed_bow_lemma,\n",
    "    sift_tfidf_stemmed, orb_tfidf_stemmed,\n",
    "    sift_weighed_tfidf_stemmed, orb_weighed_tfidf_stemmed,\n",
    "    sift_tfidf_lemma, orb_tfidf_lemma,\n",
    "    sift_weighed_tfidf_lemma, orb_weighed_tfidf_lemma,\n",
    "    sift_price_bow_stemmed, orb_price_bow_stemmed,\n",
    "    sift_weighed_price_bow_stemmed, orb_weighed_price_bow_stemmed, \n",
    "    sift_price_bow_lemma, orb_price_bow_lemma,\n",
    "    sift_weighed_price_bow_lemma, orb_weighed_price_bow_lemma,\n",
    "    sift_price_tfidf_stemmed, orb_price_tfidf_stemmed,\n",
    "    sift_weighed_price_tfidf_stemmed, orb_weighed_price_tfidf_stemmed,\n",
    "    sift_price_tfidf_lemma, orb_price_tfidf_lemma,\n",
    "    sift_weighed_price_tfidf_lemma, orb_weighed_price_tfidf_lemma\n",
    "]\n",
    "\n",
    "print(\"Number of combination:\", len(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77bf971-d85b-4b9e-9439-c0a8539a2081",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>At this point, we have 40 combinations</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30eb79d-06aa-480d-bbdd-a7a8010b00e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">7.2. Data preprocessing</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27743564-a4ec-4a97-a1a4-13618125cf5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>All features are numerican in diferents ranges.<br>At the same time, retail_price doesn't have a normal distribution. So, we are going to use QuantileTransformer to treat the features</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d11c18-b159-4dc5-a811-ffdceffeb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datasets)):\n",
    "    \n",
    "    # Getting columns and index of dataset\n",
    "    df_columns = datasets[i].columns\n",
    "    df_index = datasets[i].index\n",
    "        \n",
    "    # Getting the dataset name\n",
    "    name = [x for x in globals() if globals()[x] is datasets[i]][0]\n",
    "    \n",
    "    # All features are numerical\n",
    "    # numerical_pipeline = make_pipeline(StandardScaler())\n",
    "    numerical_pipeline = make_pipeline(QuantileTransformer(random_state=42, output_distribution=\"uniform\"))\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "                (numerical_pipeline, df_columns)\n",
    "    )\n",
    "    \n",
    "    data_scaled = preprocessor.fit_transform(datasets[i])\n",
    "    globals()[name] = pd.DataFrame(data_scaled, index=df_index, columns=df_columns)\n",
    "    \n",
    "    datasets[i] = globals()[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eaa58f-d982-4213-9c2b-38e57bf6f879",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>Now, the dataset has been preprocesed</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e5fdd-291b-4e52-b0af-45438db85f6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">7.3. PCA dimension reduction</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b49a04-6c62-459f-92ea-b3984e1f898e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's see the number of feature by dataset</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a900a4-4b27-4c01-bfa1-60788f992ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_dataset_names, orb_dataset_names, no_imgs_dataset_names = [{} for i in range(3)]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    \n",
    "    # Getting the dataset name\n",
    "    name = [x for x in globals() if globals()[x] is datasets[i]][0]\n",
    "    \n",
    "    if \"sift\" in name :\n",
    "        sift_dataset_names[name] = datasets[i].shape[1]\n",
    "    elif \"orb\" in name :\n",
    "        orb_dataset_names[name] = datasets[i].shape[1]\n",
    "    else:\n",
    "        no_imgs_dataset_names[name] = datasets[i].shape[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cf619-f2dd-43bf-99de-c89cdfb941b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 7))\n",
    "plot = sns.barplot(x=list(no_imgs_dataset_names.keys()), y=list(no_imgs_dataset_names.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".0f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(no_imgs_dataset_names.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Number of feature\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"Number of features by dataset - without image features\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f81dfe-84b5-471f-b58d-ac7fbc863a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plot = sns.barplot(x=list(sift_dataset_names.keys()), y=list(sift_dataset_names.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".0f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(sift_dataset_names.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Number of feature\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"Number of features by dataset - SIFT\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0518b84-4f58-4989-bb36-998055640ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plot = sns.barplot(x=list(orb_dataset_names.keys()), y=list(orb_dataset_names.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".0f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(orb_dataset_names.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Number of feature\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"Number of features by dataset - ORB\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513ce7d-42bf-442e-95d6-b82be312cb42",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's reduced the dimension through PCA</p>\n",
    "    <p>We are going to keep only <b>80% of variance</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a2582-2953-49bb-b49d-ecef4068e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_dataset_pca, orb_dataset_pca, no_imgs_dataset_pca = [{} for i in range(3)]\n",
    "\n",
    "datasets_pca = []\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    \n",
    "    # Getting the dataset name\n",
    "    name = [x for x in globals() if globals()[x] is datasets[i]][0]\n",
    "    \n",
    "    globals()[\"pca_\" + name] = PCA(n_components=0.80)\n",
    "    globals()[name + \"_pca\"] = globals()[\"pca_\" + key].fit_transform(datasets[i])\n",
    "    \n",
    "    if \"sift\" in name :\n",
    "        sift_dataset_pca[name] = globals()[name + \"_pca\"].shape[1]\n",
    "    elif \"orb\" in name :\n",
    "        orb_dataset_pca[name] = globals()[name + \"_pca\"].shape[1]\n",
    "    else:\n",
    "        no_imgs_dataset_pca[name] = globals()[name + \"_pca\"].shape[1]\n",
    "        \n",
    "    datasets_pca.append(globals()[name + \"_pca\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83d1be-8430-4866-8fa5-2bd42cdaa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 7))\n",
    "plot = sns.barplot(x=list(no_imgs_dataset_pca.keys()), y=list(no_imgs_dataset_pca.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".0f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(no_imgs_dataset_pca.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Number of feature\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"# of features by dataset - No image / After PCA\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5dfefd-6110-4f03-bce6-bd91569c0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plot = sns.barplot(x=list(sift_dataset_pca.keys()), y=list(sift_dataset_pca.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".0f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(sift_dataset_pca.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Number of feature\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"Number of features by dataset - SIFT / after PCA\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0dd04-1542-4516-85b4-7e8e55fd4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plot = sns.barplot(x=list(orb_dataset_pca.keys()), y=list(orb_dataset_pca.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".0f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(orb_dataset_pca.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Number of feature\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"Number of features by dataset - ORB / after PCA\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0994a423-6bbe-4a4b-8e39-630641f950f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>We can see how the number is feature have been reduced more than a half</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddab0af-ed83-48e4-8328-62eab4796dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting some dataset and list\n",
    "for df in datasets:\n",
    "    \n",
    "    name = [x for x in globals() if globals()[x] is df][0]\n",
    "    del globals()[name]\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "datasets.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a9ac8-3bd7-4207-a205-05c813c50b32",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">7.4. T-SNE dimension reduction</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11047f8-9e48-48c1-8592-1da762019e3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>First, we are going to <b>Encode</b> through LabelEncoder the first level of the tree categories </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678c648-c30a-41d1-bb6f-a6766aac0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_data[\"category_encode\"] =df_data[[\"category_1\"]].apply(le.fit_transform)\n",
    "df_data[[\"category_1\", \"category_encode\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71ff3b-d563-4599-917c-9af25a195151",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's reduced the dimension through T-SNE</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537916d-54a3-4a08-96ba-9059cea86698",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_tsne = []\n",
    "\n",
    "for i in range(len(datasets_pca)):\n",
    "    \n",
    "    # Getting the dataset name\n",
    "    name = [x for x in globals() if globals()[x] is datasets_pca[i]][0]\n",
    "    \n",
    "    globals()[\"tsne_\" + name] = TSNE(n_components=3, perplexity=30, \n",
    "                                     n_iter=2000, init=\"random\",\n",
    "                                     random_state=6, learning_rate=\"auto\")\n",
    "    X_tsne = globals()[\"tsne_\" + name].fit_transform(datasets_pca[i])\n",
    "    \n",
    "    globals()[name + \"_tsne\"] = pd.DataFrame(X_tsne[:, 0:3], columns=[\"tsne1\", \"tsne2\", \"tsne3\"])\n",
    "    globals()[name + \"_tsne\"][\"class_encode\"] = df_data[\"category_encode\"]\n",
    "    globals()[name + \"_tsne\"][\"class\"] = df_data[\"category_1\"]\n",
    "    \n",
    "    datasets_tsne.append(globals()[name + \"_tsne\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd428f-e9be-4f82-bd2b-a4b3ddea84a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at some datasets afters tsne</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6329f5-27f4-4875-8054-a6959779746c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_stemmed_pca_tsne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba06f9-2d9e-4fea-8bf7-b1fdce29d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_weighed_price_tfidf_stemmed_pca_tsne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912cef90-f8f8-429d-936c-9b32d4d3492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting some dataset and list\n",
    "for df in datasets_pca:\n",
    "    \n",
    "    name = [x for x in globals() if globals()[x] is df][0]\n",
    "    del globals()[name]\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "datasets_pca.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9b3ad-5ecf-428b-bb18-c393614dc5ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">7.5. Clusterization</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2a607-6e43-4709-874b-af61a917e7d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">7.5.1. KMeans</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70236a6a-b001-4c83-a2fc-1cbd528a269a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>The number of cluster based on the first level of the tree categories</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3656c-a6d9-433e-85a0-e8d2f04003e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = df_data[\"category_1\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1d88c-1cd7-488f-9390-7775dbae5d88",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's do the clusterization</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0361f-1739-413d-a0dc-e6190f688e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_ari, orb_ari, no_img_ari = [{} for i in range(3)]\n",
    "\n",
    "datasets_cluster = []\n",
    "\n",
    "for i in range(len(datasets_tsne)):\n",
    "    \n",
    "    df_subset = datasets_tsne[i].drop(columns=[\"class_encode\", \"class\"])\n",
    "    \n",
    "    # Getting the dataset name\n",
    "    name = [x for x in globals() if globals()[x] is datasets_tsne[i]][0]\n",
    "    name = re.sub(\"\\_pca_tsne$\", \"\", name)\n",
    "    \n",
    "    kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters,\n",
    "                    max_iter=1000, random_state=10) \n",
    "    \n",
    "    cluster_labels = kmeans.fit_predict(df_subset)\n",
    "    datasets_tsne[i][\"cluster\"] = cluster_labels\n",
    "    \n",
    "    globals()[name] = datasets_tsne[i].copy()\n",
    "    \n",
    "    # Calculating ARI based on the first level of the tree categories\n",
    "    ari = adjusted_rand_score(datasets_tsne[i][\"class_encode\"], datasets_tsne[i][\"cluster\"])\n",
    "    \n",
    "    # Saving the results based on the features\n",
    "    if \"sift\" in name :\n",
    "        sift_ari[name] = ari\n",
    "    elif \"orb\" in name :\n",
    "        orb_ari[name] = ari\n",
    "    else:\n",
    "        no_img_ari[name] = ari\n",
    "        \n",
    "    datasets_cluster.append(globals()[name])\n",
    "    \n",
    "# Ordering the results\n",
    "sift_ari = dict(sorted(sift_ari.items(), key=operator.itemgetter(1), reverse=True))\n",
    "orb_ari = dict(sorted(orb_ari.items(), key=operator.itemgetter(1), reverse=True))\n",
    "no_img_ari = dict(sorted(no_img_ari.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474fbd4a-7a7a-4f65-9822-928a6640ca2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at some datasets afters clusterization</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0886c-25dd-4c7c-a9b5-9682e3f0b96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a1a48-25bd-4a70-9745-c91a6d688272",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_weighed_price_tfidf_stemmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98c602-6473-4864-ad49-e184163b7c4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">7.5.2. Adjusted Rand Score</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02638053-bf91-4e23-9ae9-c564100bd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 7))\n",
    "plot = sns.barplot(x=list(no_img_ari.keys()), y=list(no_img_ari.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".3f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(no_img_ari.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Number of feature\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"Adjusted Rand Score\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b9a04-3440-4fe1-8ecd-487203be52ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>The datasets based on <b>TF-IDF</b> have gotten the best results compared to <b>BoW</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad534f-7737-43fe-8fe7-1c8ebb4eceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plot = sns.barplot(x=list(sift_ari.keys()), y=list(sift_ari.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".3f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(sift_ari.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Adjusted Rand Score\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"ARI - SIFT\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8b1b7-bca3-4d4f-b3d2-926c0a80d4b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>The best results are distributed in different methodologies used</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9c88a-1252-46b1-b1f1-c1acea8f7bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plot = sns.barplot(x=list(orb_ari.keys()), y=list(orb_ari.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".3f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(orb_ari.keys()), rotation=70, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Adjusted Rand Score\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"ARI - ORB\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75888c-d2ba-46a1-8262-eb022c4bac79",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>The best results are distributed in different methodologies used</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c6148-2c12-4f67-9d64-1a574dfd25cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>We are going to select the two best results from each group</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58df113-634a-4879-821f-60963f428006",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfs = {}\n",
    "\n",
    "for dictionary in [no_img_ari, sift_ari, orb_ari]:\n",
    "    \n",
    "    for item in islice(dictionary.items(), 2):\n",
    "        final_dfs[item[0]] = item[1]\n",
    "        \n",
    "final_dfs = dict(sorted(final_dfs.items(), key=operator.itemgetter(1), reverse=True))\n",
    "final_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14170710-addc-4cfc-bdd4-e28d8c2d814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plot = sns.barplot(x=list(final_dfs.keys()), y=list(final_dfs.values()))\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), \".3f\"), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"center\", xytext=(0, 9), textcoords=\"offset points\")\n",
    "plot.set_xticklabels(labels=list(final_dfs.keys()), rotation=50, size=12, horizontalalignment=\"right\")\n",
    "plt.ylabel(\"Adjusted Rand Score\", size=12)\n",
    "plt.xlabel(\"Dataset\", size=12)\n",
    "plt.title(\"Best ARI\", size=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699091a0-1ffc-4de0-9855-dd7a159e0df7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>The best results are based on features without images features</p>\n",
    "    <p>We can suppose that the images had added noise into the datasets to analyze what makes that variance is higher distributed</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c1bf0-6227-4fb4-bd25-27f7f9ec098e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">7.5.2. Benchmark KMeans</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3cc13-bee5-419a-b9f3-974a2b4cb43c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, we are going to do a benchmark among the best results</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0ecb9-0b77-46fa-a71f-d951a74e7ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for key, value in final_dfs.items():\n",
    "    \n",
    "    df_subset = globals()[key].drop(columns=[\"class\", \"class_encode\", \"cluster\"])\n",
    "    \n",
    "    kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters,\n",
    "                max_iter=1000, random_state=10) \n",
    "    \n",
    "    results.append(benchmark_kmeans(key, kmeans, n_clusters, df_subset))  \n",
    "\n",
    "header = [\n",
    "    \"dataset\", \"clusters\", \"time\", \"inertia\", \n",
    "    \"calinski-harabasz\", \"davies-bouldin\", \"silhouette\"\n",
    "]\n",
    "\n",
    "print(tabulate(results, header))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca08b2f-bc40-43fc-9ea4-a13939a457cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <p><b>Observations / Conclusions</b></p>\n",
    "    <p>The best results are based on features without images features</p>\n",
    "    <p>We can suppose that the images had added noise into the datasets to analyze what makes that variance is higher distributed</p>\n",
    "    <ul style=\"list-style-type: square;\">\n",
    "        <li><b>inertia</b>: 57772.9 (orb_tfidf_lemma)</li>\n",
    "        <li><b>calinski-harabasz</b>: 1651.08 (tfidf_lemma_price)</li>\n",
    "        <li><b>davies-bouldin</b>: 0.65823 (tfidf_lemma_price)</li>\n",
    "        <li><b>silhouette</b>: 0.521855 (tfidf_lemma_price)</li>\n",
    "    </ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c329e-4474-4d58-8022-9cc1a0367fc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">7.5.4. Visual analysis</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af6936-21c6-461b-9c75-803e1e16a84b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's plot the data based on T-SNE</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799a0fc-7506-49cd-b97d-82411d896505",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in final_dfs.items():\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, sharex=True, figsize=(16, 8))\n",
    "    fig.suptitle(key.upper() + \" - ARI score: \" + str(round(value, 2)),\n",
    "                 fontsize=18, fontweight=\"bold\")    \n",
    "\n",
    "    sns.scatterplot(ax=axes[0], x=\"tsne1\", y=\"tsne2\", hue=\"class\", \n",
    "                    data=globals()[key], legend=\"brief\",\n",
    "                    palette=sns.color_palette(\"tab10\", n_colors=7),\n",
    "                    s=50, alpha=0.6)\n",
    "    axes[0].legend(loc=\"best\", prop={\"size\": 12},\n",
    "              title=\"Categories\")\n",
    "    axes[0].set_title(\"True categories\", fontsize=14)\n",
    "\n",
    "    sns.scatterplot(ax=axes[1], x=\"tsne1\", y=\"tsne2\", hue=\"cluster\", \n",
    "                    data=globals()[key], legend=\"brief\",\n",
    "                    palette=sns.color_palette(\"tab10\", n_colors=7),\n",
    "                    s=50, alpha=0.6)\n",
    "    axes[1].legend(loc=\"best\", prop={\"size\": 12},\n",
    "              title=\"Clusters\")\n",
    "    axes[1].set_title(\"Clusters\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03187c2-7e68-48c4-b0f6-e81a86ba50c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37f240-3fab-458b-814c-53ac3d236eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff55d9-b9f1-40d2-b1e7-d9a0ef07f267",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150673c4-3936-48c4-bb4a-84df5273c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir='logs/test/'\n",
    "\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960d22f-1d3e-4bd5-acf6-5a37d7fe73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "    for subwords in encoder.subwords:\n",
    "        f.write(\"{}\\n\".format(subwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9c42d-b50c-4a7d-83c6-dafbcd725f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33ef0f-72f5-4622-be91-34059f0e5072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf03b2-5f65-4da4-8eb8-2858fad3d137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b310f8f-a9c8-44b6-802a-e53aaec00f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8c672-2ff1-4426-a753-264cc2cdb138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06496140-d82d-41d6-8b86-d40bb41a9ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b9bf5-0749-4c3d-98e9-7c7200ca8050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3e1ab-622d-4593-a6af-c0641c78784f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d20389-73d0-482c-8682-3afb2b39e9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723bb348-ec39-42ab-8729-a76ddcec68ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33f53c-582d-4312-9318-b03a1e91903b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a6802-dd79-4cfc-b30c-8be2a03d26b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cf766-4b0d-4e87-9e9b-a216f23284fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1587605a-faba-4a05-adb1-02a517a13d40",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f75a5e-1acb-413c-ab56-6d90fc32b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa418608-e86a-459b-873e-3ac6f711583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "path = \"/home/\"\n",
    " \n",
    "# Join various path components\n",
    "print(os.path.join(path, \"User/Desktop/\", \"file.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf5477c-8e92-4804-b2ff-3d7296c4a208",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7002a478-0f2c-4852-be42-b13912758ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = \"logs/\" # Path to save the embedding and checkpoints generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37d8f179-196c-402b-a982-6d1e038103d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = pd.read_csv(r\"temp_datasets\\sift_weighed_price_tfidf_lemma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "942b3faf-db95-496f-aadf-7588be1047e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tsne[[\"tsne1\", \"tsne2\", \"tsne3\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dd6c833-5312-4cde-9a1f-554b566aee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(LOG_DIR + \"features.txt\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "515d2c31-333f-4f4d-9840-db548957cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(LOG_DIR + \"features.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8ae9174-0a1c-44c8-839f-e01975d0a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = tsne[[\"cluster\"]].copy()\n",
    "md.to_csv(LOG_DIR + \"metadata.tsv\", sep='\\t', index=False, header=False)\n",
    "metadata = os.path.join(LOG_DIR, 'metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "859d9445-699a-4179-adf4-c3c3083bd9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.119587 ,  58.436615 ,   3.8751395],\n",
       "       [ 39.798027 ,  66.64062  ,  22.980347 ],\n",
       "       [ 25.765162 ,  55.383446 ,  30.379305 ],\n",
       "       ...,\n",
       "       [-42.181313 ,  29.136429 ,  48.90622  ],\n",
       "       [ 50.663353 , -34.374763 , -49.803753 ],\n",
       "       [-80.76941  ,   9.1211195,  35.4123   ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_vector = np.loadtxt(LOG_DIR + \"features.txt\")\n",
    "features_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3834548f-80e7-4af2-be61-69f1761b7e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1050, 3) dtype=float64, numpy=\n",
       "array([[ 56.119587 ,  58.436615 ,   3.8751395],\n",
       "       [ 39.798027 ,  66.64062  ,  22.980347 ],\n",
       "       [ 25.765162 ,  55.383446 ,  30.379305 ],\n",
       "       ...,\n",
       "       [-42.181313 ,  29.136429 ,  48.90622  ],\n",
       "       [ 50.663353 , -34.374763 , -49.803753 ],\n",
       "       [-80.76941  ,   9.1211195,  35.4123   ]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tf.Variable(features_vector)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "323e9b2e-a4e7-4eee-91be-aa189864d442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/embedding.ckpt-1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(LOG_DIR, \"embedding.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41dd96d4-4cf8-4e59-bac3-a6c09085722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77d3c646-65ae-46e2-9ae4-c49f80907a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "\n",
    "# embedding.tensor_name = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d08a11c-3421-443f-9eaf-52aa1df88365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding.metadata_path = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b8db121-c9bb-4f8c-92ac-fd9ff5990513",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector.visualize_embeddings(LOG_DIR, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99ed97-2d23-41e2-9f56-057e77cb28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir /logs/tf_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b80dd-1439-4535-ba9d-8a50c28cc573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee35ac-bb9f-4572-abeb-b4da8e4699d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f9489-6b0c-4a62-a230-af5a0e18f6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facab62d-cb45-4647-80af-3bed91b105a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e924201-1b70-4ea6-a272-a8d2a05fc4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e95365-d405-4070-b567-12faf8192818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb7446-b130-4481-9c43-3068a80953cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818b20e-ac7b-466e-85cd-c754f5f0cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando los archivos a leer\n",
    "metadata = tsne[[\"cluster\"]].copy()\n",
    "metadata.to_csv(LOG_DIR + \"metadata.tsv\", sep='\\t', index=False, header=False)\n",
    "\n",
    "                \n",
    "features = tsne[[\"tsne1\", \"tsne2\", \"tsne3\"]].copy()\n",
    "features.to_csv(LOG_DIR + \"features.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32e6f1-e5af-4622-8dbe-5b97ba4f7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3756fc7-8b18-4435-b09c-16d93509e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = pd.read_csv(r\"temp_datasets\\sift_weighed_price_tfidf_lemma.csv\")\n",
    "# tsne.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "# tsne.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d21502-39d0-4a75-9979-d99aaf53d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = os.path.join(LOG_DIR, \"features.txt\")\n",
    "print(features)\n",
    "metadata = os.path.join(LOG_DIR, \"metadata.tsv\")\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93b0a0-d8f0-4887-b6ed-54d64afc7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vector = np.loadtxt(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8110c-c8ec-4eec-8b7d-55b9864ff997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f187fb6-7042-40fc-9403-c8bfa290dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(features_vector)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9a482-8b28-481a-ac56-7d75a828746a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2b796-afd5-403f-92e4-46d1f640b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(LOG_DIR, \"embedding.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06fca2-062e-4497-9168-f0702598eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce34675-c3e7-4f64-be31-670938da77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.tensor_name = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e223c-44ff-45a9-b2a4-3aa682b34727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding.metadata_path = \"metadata.tsv\"\n",
    "embedding.metadata_path = metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869927a-b2e7-4c08-bdec-e67cc38e7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector.visualize_embeddings(LOG_DIR, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc380bec-a5b7-4d3b-aa54-5c526c9f23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir /logs/tf_files/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e60b3-53d3-4c90-b949-5300b5505260",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- IMDB EXAMPLE ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd593b-089f-455d-b984-4b60763af479",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3058b41-092a-4a50-b3b7-7aa56c6ea32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d5766-5b57-4dff-a96d-288ca9938b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7e694-6fdf-499b-8e54-b3363a794b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcdc84-4cb0-424c-b76d-219cd53f4d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bd72a-b246-4c05-b54d-7a79c76d9e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edc4aa33-842c-40bd-8a56-8a9f9d4a0122",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- IMDB EXAMPLE ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d6bff-c841-4eac-8ebf-85e59854daf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733af04a-7f3a-49c4-ae30-1df9e4139ec8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901c900-11cc-4e28-8751-f7c4f5408bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cddc895-ff0e-4d36-a34c-fb4e9425bb90",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c5345-f297-4b3c-a356-3443112c2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tsne[[\"tsne1\", \"tsne2\", \"tsne3\"]].copy()\n",
    "features.to_csv(LOG_DIR + \"features.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce12ae-d0a7-4fb7-aa64-e912e34c75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[key].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54852189-48cc-4e70-9530-8afe1713e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in final_dfs.items():\n",
    "    globals()[key].to_csv(\"temp_datasets\\\\\" + key + \".csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c3488a-8210-436b-9db4-a0aa1c2978ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18adaffe-679b-4fa7-a081-2aef83195527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419c8f4-fb4b-4cb7-81bc-a42c0b99e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_tfidf_lemma[[\"tsne1\", \"tsne2\"]].to_csv(\"test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e6169-914b-458b-b301-3237135852e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_tfidf_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699e8ec-5e64-49c9-ab68-088e72525395",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframe.to_csv('/path/to/filename', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30abf2-5b3f-41f0-bade-6402d6b8ef28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c12fa38-b0bd-4f29-8a37-3988cf6d043c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "url = 'https://projector.tensorflow.org/'\n",
    "\n",
    "IPython.display.IFrame(url, width=1333, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd059f-d0ba-4eec-8434-50314724476f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19997fe-bfc6-429d-bc73-26ba17fc51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb85095-f06d-46b5-9fb4-df60cc07c866",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FF5733;\" >\n",
    "    <h1 style=\"margin: auto; padding: 20px; color:#fff; \">--------- FLAG POSITION ---------</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dac3b7-c917-475b-8836-280fd1434a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74bce6-f22d-47a8-92e4-7ba222e4ef76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42abd8-5c1c-4032-a9be-4581ab814cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de84de-6d27-4472-ada1-d69e5a319101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9deb0-a3eb-4ccb-a20d-5d93f0219469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f8019-8b29-4c7a-8a36-885e52ad3bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748d24e-1b8e-43da-bc1a-912fa7d2a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_with_tensorflow(path, image):\n",
    "    \n",
    "    # reading the image\n",
    "    image = tf.io.read_file(path + image)\n",
    "    \n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "    # resize the image to the desired size for your model\n",
    "    image = tf.image.resize_with_pad(image, 100, 100)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf482b4-88a6-4e83-af74-8de8266985ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656b4b9-3491-4dd6-a1ea-3e6653101251",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_image = get_image_with_tensorflow(THUMBNAILS_IMAGES_PATH, \"0a3b5fdf77a361c2d7d9b29c259b8c4e.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb83017-f984-4e8f-8f06-4b02c8dfc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "images_pil = []\n",
    "images_embeddings = []\n",
    "labels = []\n",
    "for ind in tsne.index:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8aae22-7330-4092-b70e-6099242af0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
