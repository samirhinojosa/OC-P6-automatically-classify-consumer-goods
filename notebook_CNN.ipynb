{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55a18bb-4886-4389-b2a4-961844aeb823",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; background-color: #3F579F;\">\n",
    "    <h1 style=\"margin: auto; font-weight: bold; padding: 30px 30px 0px 30px; color:#fff;\" align=\"center\">Automatically classify consumer goods - P6</h1>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 5px 30px 0px 30px;\" >\n",
    "    <h3 style=\"width: 100%; text-align: center; float: left; font-size: 24px; color:#fff;\" align=\"center\">| Notebook - Convolutional Neural Networks |</h3>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 10px 30px 30px 30px;\">\n",
    "    <h4 style=\"width: 100%; text-align: center; float: left; font-size: 24px; color:#fff;\" align=\"center\">Data Scientist course - OpenClassrooms</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18d322-d315-43f5-ab34-37889f2033ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>In this notebook, we are going to do the image classification through Convolutional Neural Networks - CNN</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c451fcf-c67c-4173-bc81-bf530c69fd95",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">1. Libraries and functions</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f7a9e-4512-4c1f-aedd-3bb2024dc489",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">1.1. Libraries and functions</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393084d6-f300-46a9-a7bb-766eeab928a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "## TensorFlow\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "## Scikit Learn \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## Own specific functions \n",
    "from functions import *\n",
    "\n",
    "## Images paths\n",
    "THUMBNAILS_IMAGES_PATH  = \"images/Flipkart/thumbnails/\"\n",
    "ORIGINAL_IMAGES_PATH = \"images/Flipkart/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b2e06-a408-49fb-b16f-a233cb9f8c38",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">2. Importing files and Initial analysis</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0f500-24d8-41b8-9dc1-ac9819b63529",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">2.1. Importing and preparing files</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fd1d6-8eac-4bae-9115-9599a9cb7081",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    We are going to load the dateset to have data to compare the results\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc6346a-3c0a-4a8b-ac95-f931de8488ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(r\"datasets\\df_data.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aedb770-bbae-4c70-949a-554230d1fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data[[\"image\", \"category_1\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7469a71-8528-40d0-b367-ba0b7cb68baa",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">2.2. Initial analysis</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bba487b-9437-48f1-979e-e74114a48a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Header of df_data dataset\n",
      "--------------------------------------------------------------------------------\n",
      "- Dataset shape:\t\t\t 1050 rows and 2 columns\n",
      "- Total of NaN values:\t\t\t 0\n",
      "- Percentage of NaN:\t\t\t 0.0 %\n",
      "- Total of full duplicates rows:\t 0\n",
      "- Total of empty rows:\t\t\t 0\n",
      "- Total of empty columns:\t\t 0\n",
      "- Unique indexes:\t\t\t True\n",
      "- Memory usage:\t\t\t\t 24.6+ KB\n",
      "\n",
      "Detailed analysis of df_data dataset\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>records</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image</td>\n",
       "      <td>object</td>\n",
       "      <td>1050</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category_1</td>\n",
       "      <td>object</td>\n",
       "      <td>1050</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name    type  records  unique\n",
       "0       image  object     1050    1050\n",
       "1  category_1  object     1050       7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_analysis(df_data, \"df_data\", analysis_type=\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21e1ac-aa4a-4ce7-b4c2-44a134fffd47",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">3. Convolutional Neural Networks - VGG16<h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22059f95-2f01-41d7-922e-a6ab2b9f94d5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.1. Setup the model</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e690f95-8246-44f9-9866-5ef6332928e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed942d-d672-4a02-bf2b-2a80fa0144ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.2. Feature extraction</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210a3c7e-0cf0-4df3-8eac-450f8ba189a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samir\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\Image.py:2918: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13308/640233811.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mvgg16_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mvgg16_feature_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg16_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mvgg16_feature_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg16_feature_np\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1747\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1748\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1749\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1750\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg16_feature_list = []\n",
    "\n",
    "for ind in df_data.index:\n",
    "    \n",
    "    # loading images\n",
    "    image = load_img(ORIGINAL_IMAGES_PATH + \n",
    "                     df_data[\"image\"][ind],\n",
    "                     target_size=(224, 224))\n",
    "    \n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    vgg16_feature = model.predict(image)\n",
    "    vgg16_feature_np = np.array(vgg16_feature)\n",
    "    vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "\n",
    "vgg16_feature_list_np = np.array(vgg16_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40850496-a349-4115-83b7-67798a6a3465",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's see the result</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f46c76-ab03-45d7-bea2-5a2258d3c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"VGG16\"] = \"\"\n",
    "\n",
    "for ind in df_data.index:\n",
    "    df_data[\"VGG16\"][ind] = vgg16_feature_list_np[ind]\n",
    "\n",
    "df_data.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7999050-5af2-476e-a828-1689a8b7329b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Now, let's create the BoVW based on the result</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218e605-53b9-468b-8eda-aa6fa5b2279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VGG16 = np.column_stack(df_data[\"VGG16\"].values.tolist())\n",
    "df_VGG16 = pd.DataFrame(df_VGG16).T\n",
    "df_VGG16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330e5bc-d0d2-4e68-8277-28454c266bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "ax = plt.subplot(311)\n",
    "\n",
    "ax.set_title(\"Labels histogram - VGG16\", size=20, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Visual words\", size=14)\n",
    "ax.set_ylabel(\"Frequency\", size=14)\n",
    "\n",
    "ax.plot(df_VGG16[1].ravel())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92287760-506e-4fd6-8adb-f311091df9d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.3. PCA and T-SNE dimension reduction</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30823c93-ef35-4319-bc59-4b28108a73fd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at the dataset shape before doing the PCA </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49eecf6-5c52-472a-85e1-494f32db5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape: \" + str(df_VGG16.shape[0]) + \" rows and \" + \n",
    "      str(df_VGG16.shape[1]) + \" columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe77ca-d3aa-4fa4-9b47-8dd95a13cb59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Next, we are going to do the PCA </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c9400-d408-471b-a895-3aaff04ac290",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.80)\n",
    "VGG16_pca = pca.fit_transform(df_VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b24b0-e846-46f5-952b-21226bba47c5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at the dataset shape again </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c799cf4-339e-4f74-8d65-380b6892becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9812a9b-3a87-4dd4-af67-52f96720aab6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Before doing the T-SNE, we are going to <b>Encode</b> through LabelEncoder the first level of the tree categories </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468437f-fdec-4732-8879-3d4c6a0432bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_data[\"category_encode\"] =df_data[[\"category_1\"]].apply(le.fit_transform)\n",
    "df_data[[\"category_1\", \"category_encode\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216a8d0-7485-473a-bcdc-7c244c95afff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's reduced the dimension through T-SNE</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fe3ca-c661-466c-ad3e-c58496db11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30,\n",
    "            n_iter=2000, init=\"random\",\n",
    "            random_state=6, learning_rate=\"auto\")\n",
    "\n",
    "X_tsne = tsne.fit_transform(VGG16_pca)\n",
    "\n",
    "VGG16_pca_tsne = pd.DataFrame(X_tsne[:, 0:2], columns=[\"tsne1\", \"tsne2\"])\n",
    "VGG16_pca_tsne[\"class_encode\"] = df_data[\"category_encode\"]\n",
    "VGG16_pca_tsne[\"class\"] = df_data[\"category_1\"]\n",
    "\n",
    "VGG16_pca_tsne.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785d7d9-f75d-4c5d-befb-415d1847096c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.4. Clusterization</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe738e-e131-4277-9fd9-6bdeb1f418be",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">3.4.1. KMeans</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87cf468-80c0-4793-abbf-261d1b659b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>The number of cluster based on the first level of the tree categories</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929d100-a7f1-49bc-8d31-c97051a9c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = df_data[\"category_1\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e761b5-be46-4e0b-945f-f8e3d4f10f83",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's do the clusterization</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346581e-2b24-43f6-88e3-c2f8027db621",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters,\n",
    "                max_iter=1000, random_state=10)\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(VGG16_pca_tsne[[\"tsne1\", \"tsne2\"]])\n",
    "VGG16_pca_tsne[\"cluster\"] = cluster_labels\n",
    "\n",
    "# Calculating ARI based on the first level of the tree categories\n",
    "ari = adjusted_rand_score(VGG16_pca_tsne[\"class_encode\"], VGG16_pca_tsne[\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1eb25-2a7c-4b46-8fd9-0aded0a26655",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebb99f-5d6c-445b-8447-dfe9077af032",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharex=True, figsize=(16, 8))\n",
    "# fig.suptitle(key.upper() + \" - ARI score: \" + str(round(value, 2)),\n",
    "#              fontsize=18, fontweight=\"bold\")    \n",
    "\n",
    "sns.scatterplot(ax=axes[0], x=\"tsne1\", y=\"tsne2\", hue=\"class\", \n",
    "                data=VGG16_pca_tsne, legend=\"brief\",\n",
    "                palette=sns.color_palette(\"tab10\", n_colors=7),\n",
    "                s=50, alpha=0.6)\n",
    "axes[0].legend(loc=\"best\", prop={\"size\": 12},\n",
    "          title=\"Categories\")\n",
    "axes[0].set_title(\"True categories\", fontsize=14)\n",
    "\n",
    "sns.scatterplot(ax=axes[1], x=\"tsne1\", y=\"tsne2\", hue=\"cluster\", \n",
    "                data=VGG16_pca_tsne, legend=\"brief\",\n",
    "                palette=sns.color_palette(\"tab10\", n_colors=7),\n",
    "                s=50, alpha=0.6)\n",
    "axes[1].legend(loc=\"best\", prop={\"size\": 12},\n",
    "          title=\"Clusters\")\n",
    "axes[1].set_title(\"Clusters\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa43624-c58f-40af-850e-2530985139d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/valentincorad/CentraleSupelec-Projects/blob/main/Projet%205%20-%20Classifiez%20automatiquement%20des%20biens%20de%20consommation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3006ba5-204e-4ec2-98db-edf330e571ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4122cdb8-5286-4724-9e13-c644b1e91ca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h1>>>>> FLAG POSITION &lt;&lt;&lt;&lt; </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c908200-5ea0-49cc-b1c6-dc60d0727266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c564a-3fb9-4b52-9e76-11c55c098d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.3. PCA and T-SNE dimension reduction</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e602a5b-13d4-4b9e-a9c9-a65b9745261b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's look at the dataset shape before doing the PCA </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3d262-4e2b-491c-843b-b7a782f5fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape: \" + str(df_VGG16.shape[0]) + \" rows and \" + \n",
    "      str(df_VGG16.shape[1]) + \" columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd71629-5602-44ea-98f6-afe6ed604a2f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Before doing the T-SNE, we are going to <b>Encode</b> through LabelEncoder the first level of the tree categories </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d3d67-6280-4db9-b218-2457950ad86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_data[\"category_encode\"] =df_data[[\"category_1\"]].apply(le.fit_transform)\n",
    "df_data[[\"category_1\", \"category_encode\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9dff4-692c-4988-bd9c-b89c231870be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's reduced the dimension through T-SNE</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13076672-0ef5-465f-8bce-c3b5c4d81a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30,\n",
    "            n_iter=2000, init=\"random\",\n",
    "            random_state=6, learning_rate=\"auto\")\n",
    "\n",
    "X_tsne = tsne.fit_transform(df_VGG16)\n",
    "\n",
    "VGG16_tsne = pd.DataFrame(X_tsne[:, 0:2], columns=[\"tsne1\", \"tsne2\"])\n",
    "VGG16_tsne[\"class_encode\"] = df_data[\"category_encode\"]\n",
    "VGG16_tsne[\"class\"] = df_data[\"category_1\"]\n",
    "\n",
    "VGG16_tsne.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665c35b-4e9d-42ae-94d0-bfbae40f947c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.4. Clusterization</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353999f-15e8-47ca-b4ed-c2f2415b608a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h4 style=\"margin: auto; padding: 20px; color:#fff; \">3.4.1. KMeans</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975333d-7db8-42fc-b275-788522fd8191",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>The number of cluster based on the first level of the tree categories</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4de469-0831-44aa-bdea-96a898ea280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = df_data[\"category_1\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce3079-6130-4833-96a6-ef4a64e33a85",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's do the clusterization</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbf39a-5bef-47bc-a553-4f506d1e161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters,\n",
    "                max_iter=1000, random_state=10)\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(VGG16_tsne[[\"tsne1\", \"tsne2\"]])\n",
    "VGG16_tsne[\"cluster\"] = cluster_labels\n",
    "\n",
    "# Calculating ARI based on the first level of the tree categories\n",
    "ari = adjusted_rand_score(VGG16_tsne[\"class_encode\"], VGG16_tsne[\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0b93c-af53-408f-8d7e-e58d1a90338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57304e9-5035-4cac-8dc4-ceef2ddca611",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "fig, axes = plt.subplots(1, 2, sharex=True, figsize=(16, 8))\n",
    "# fig.suptitle(key.upper() + \" - ARI score: \" + str(round(value, 2)),\n",
    "#              fontsize=18, fontweight=\"bold\")    \n",
    "\n",
    "sns.scatterplot(ax=axes[0], x=\"tsne1\", y=\"tsne2\", hue=\"class\", \n",
    "                data=VGG16_tsne, legend=\"brief\",\n",
    "                palette=sns.color_palette(\"tab10\", n_colors=7),\n",
    "                s=50, alpha=0.6)\n",
    "axes[0].legend(loc=\"best\", prop={\"size\": 12},\n",
    "          title=\"Categories\")\n",
    "axes[0].set_title(\"True categories\", fontsize=14)\n",
    "\n",
    "sns.scatterplot(ax=axes[1], x=\"tsne1\", y=\"tsne2\", hue=\"cluster\", \n",
    "                data=VGG16_tsne, legend=\"brief\",\n",
    "                palette=sns.color_palette(\"tab10\", n_colors=7),\n",
    "                s=50, alpha=0.6)\n",
    "axes[1].legend(loc=\"best\", prop={\"size\": 12},\n",
    "          title=\"Clusters\")\n",
    "axes[1].set_title(\"Clusters\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085832c7-a689-4c1e-a6d8-87feee0659a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13cb9987-fc9e-40a5-9479-d933828a0c17",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h1>>>>> FLAG POSITION &lt;&lt;&lt;&lt; </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a786e-92b1-4582-b7e5-6932703d6746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b056515-2aaa-4580-86d0-d47ca895c6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6238244-74af-4a39-a65a-646f4dc06752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d385dd-805f-42b4-a5e4-579263bc2f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20ad14-0302-487d-aeee-95c5425bef8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed7b72-b092-4fcc-96da-cd2a1101febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VGG16 = extract_data(\"VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40650d2-586c-4a8a-bd21-1f32e96ba827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VGG16.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b9bda-a049-454d-888d-eb5e66e210f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Let's reduced the dimension through T-SNE</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99052db-3547-4739-a801-ab77071b091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30, \n",
    "            n_iter=2000, init=\"random\",\n",
    "            random_state=6, learning_rate=\"auto\")\n",
    "\n",
    "X_tsne = tsne.fit_transform(datasets_pca[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ea4ce-9e4d-4275-a67c-23d8ad8865c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h1>>>>> FLAG POSITION &lt;&lt;&lt;&lt; </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe50f2-b283-4887-a88d-5a9b6e338c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d194214-c556-4724-bc50-5903f3179808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb162e42-efb0-4b98-8909-912b6b969b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee221ca-9860-4ae0-a7de-faa8041e6a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb939d0-f5f2-4652-9613-3f0d56f7cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"datasets\\flipkart_com-ecommerce_sample_1050.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73036c-d2e1-4d17-93f6-8a847eb73360",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    #print(df[\"image\"][ind])\n",
    "    \n",
    "    image = load_img(ORIGINAL_IMAGES_PATH + df[\"image\"][ind],\n",
    "                     target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], \n",
    "                           image.shape[1], \n",
    "                           image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    y_pred = model.predict(image)\n",
    "    label = decode_predictions(y_pred, top=1)\n",
    "    \n",
    "    print(label)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d67ea5-1ad8-47ae-9e3a-232f257da286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811741a-5fe7-4e74-8145-44cb79ffc926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
